# SWE-bench æ•°æ®é›†ç”Ÿæˆå‚æ•°è¯¦è§£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» `create_text_dataset.py` çš„æ‰€æœ‰å‚æ•°åŠå…¶ä½¿ç”¨æ–¹æ³•ã€‚

---

## ğŸ“‹ å‚æ•°æ€»è§ˆ

```bash
python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path <è·¯å¾„æˆ–åç§°> \
    --splits train test \
    --validation_ratio 0.01 \
    --output_dir <è¾“å‡ºç›®å½•> \
    --retrieval_file <æ£€ç´¢ç»“æœæ–‡ä»¶> \
    --prompt_style style-3 \
    --file_source bm25 \
    --k 10 \
    --max_context_len 16000 \
    --tokenizer_name cl100k \
    --push_to_hub_user <HuggingFaceç”¨æˆ·å>
```

---

## 1ï¸âƒ£ `--dataset_name_or_path`

### ğŸ“– è¯´æ˜
æŒ‡å®šè¾“å…¥æ•°æ®é›†çš„æ¥æº

### ğŸ¯ ç±»å‹
`str`

### ğŸ’¡ é»˜è®¤å€¼
`"SWE-bench/SWE-bench"`

### ğŸ“ ç”¨é€”
- **HuggingFace æ•°æ®é›†**: ä½¿ç”¨æ•°æ®é›†åç§°,å¦‚ `princeton-nlp/SWE-bench`
- **æœ¬åœ°æ•°æ®é›†**: ä½¿ç”¨ `save_to_disk()` ä¿å­˜çš„ç›®å½•è·¯å¾„

### ğŸ’» ç¤ºä¾‹
```bash
# ä½¿ç”¨ HuggingFace æ•°æ®é›†
--dataset_name_or_path princeton-nlp/SWE-bench

# ä½¿ç”¨æœ¬åœ°æ•°æ®é›†
--dataset_name_or_path /path/to/saved/dataset

# ä½¿ç”¨ SWE-bench Lite
--dataset_name_or_path princeton-nlp/SWE-bench_Lite
```

### ğŸ“Œ æ³¨æ„
- æ•°æ®é›†å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µ:
  - `instance_id`: ä»»åŠ¡å”¯ä¸€æ ‡è¯†
  - `problem_statement`: é—®é¢˜æè¿°
  - `patch`: æ­£ç¡®çš„è¡¥ä¸
  - `repo`: ä»“åº“åç§°
  - `base_commit`: åŸºç¡€ commit SHA

---

## 2ï¸âƒ£ `--splits`

### ğŸ“– è¯´æ˜
æŒ‡å®šè¦å¤„ç†çš„æ•°æ®é›†åˆ†å‰²(split)

### ğŸ¯ ç±»å‹
`list[str]` (å¯ä»¥æŒ‡å®šå¤šä¸ª)

### ğŸ’¡ é»˜è®¤å€¼
`["train", "test"]`

### ğŸ“ ç”¨é€”
é€‰æ‹©æ•°æ®é›†ä¸­çš„å“ªäº›åˆ†å‰²è¿›è¡Œå¤„ç†

### ğŸ’» ç¤ºä¾‹
```bash
# åªå¤„ç†æµ‹è¯•é›†
--splits test

# å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
--splits train test

# å¤„ç†æ‰€æœ‰åˆ†å‰²
--splits train test dev
```

### ğŸ“Œ å¸¸è§åˆ†å‰²
- `train`: è®­ç»ƒé›†
- `test`: æµ‹è¯•é›†
- `dev`: å¼€å‘é›†(å¦‚æœå­˜åœ¨)
- `validation`: éªŒè¯é›†(å¦‚æœå­˜åœ¨)

---

## 3ï¸âƒ£ `--validation_ratio`

### ğŸ“– è¯´æ˜
ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†å‡ºéªŒè¯é›†çš„æ¯”ä¾‹

### ğŸ¯ ç±»å‹
`float`

### ğŸ’¡ é»˜è®¤å€¼
`0.01` (1%)

### ğŸ“ ç”¨é€”
è‡ªåŠ¨ä»è®­ç»ƒé›†ä¸­åˆ†å‰²å‡ºä¸€éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†

### ğŸ’» ç¤ºä¾‹
```bash
# ä½¿ç”¨ 1% çš„è®­ç»ƒæ•°æ®ä½œä¸ºéªŒè¯é›†
--validation_ratio 0.01

# ä½¿ç”¨ 5% çš„è®­ç»ƒæ•°æ®ä½œä¸ºéªŒè¯é›†
--validation_ratio 0.05

# ä¸åˆ›å»ºéªŒè¯é›†
--validation_ratio 0
```

### ğŸ“Œ è¡Œä¸º
- åªå¯¹ `train` åˆ†å‰²ç”Ÿæ•ˆ
- ä½¿ç”¨ `train_test_split()` æ–¹æ³•,éšæœºç§å­ä¸º 42
- ç”Ÿæˆåçš„æ•°æ®é›†ä¼šåŒ…å« `validation` åˆ†å‰²

---

## 4ï¸âƒ£ `--output_dir`

### ğŸ“– è¯´æ˜
ä¿å­˜ç”Ÿæˆçš„æ•°æ®é›†çš„ç›®å½•

### ğŸ¯ ç±»å‹
`str` (å¿…éœ€å‚æ•°,é™¤éä½¿ç”¨ `--push_to_hub_user`)

### ğŸ’¡ é»˜è®¤å€¼
æ— 

### ğŸ“ ç”¨é€”
æŒ‡å®šæ•°æ®é›†çš„ä¿å­˜ä½ç½®

### ğŸ’» ç¤ºä¾‹
```bash
# ä¿å­˜åˆ°æœ¬åœ°ç›®å½•
--output_dir ./processed_datasets

# ä¿å­˜åˆ°ç»å¯¹è·¯å¾„
--output_dir /data/swebench/oracle_dataset
```

### ğŸ“Œ è¾“å‡ºæ–‡ä»¶å‘½å
è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶åæ ¼å¼:
```
{dataset_name}__{prompt_style}__fs-{file_source}[__k-{k}][__mcc-{max_context_len}-{tokenizer_name}]
```

ç¤ºä¾‹:
```
SWE-bench__style-3__fs-bm25__k-10__mcc-16000-cl100k/
â”œâ”€â”€ dataset_dict.json
â”œâ”€â”€ test/
â””â”€â”€ train/
```

---

## 5ï¸âƒ£ `--retrieval_file`

### ğŸ“– è¯´æ˜
BM25 æ£€ç´¢ç»“æœæ–‡ä»¶çš„è·¯å¾„

### ğŸ¯ ç±»å‹
`str`

### ğŸ’¡ é»˜è®¤å€¼
`None`

### ğŸ“ ç”¨é€”
å½“ä½¿ç”¨ `--file_source bm25` æ—¶,æä¾›é¢„å…ˆè®¡ç®—çš„æ£€ç´¢ç»“æœ

### ğŸ’» ç¤ºä¾‹
```bash
# å…ˆè¿è¡Œ BM25 æ£€ç´¢
python -m swebench.inference.make_datasets.bm25_retrieval \
    --dataset_name princeton-nlp/SWE-bench \
    --output_file ./bm25_results.jsonl

# ä½¿ç”¨æ£€ç´¢ç»“æœ
--retrieval_file ./bm25_results.jsonl
```

### ğŸ“Œ æ–‡ä»¶æ ¼å¼
JSONL æ ¼å¼,æ¯è¡ŒåŒ…å«:
```json
{
  "instance_id": "django__django-12345",
  "hits": [
    {"docid": "path/to/file1.py", "score": 15.2},
    {"docid": "path/to/file2.py", "score": 12.8},
    ...
  ]
}
```

### âš ï¸ æ³¨æ„
- ä»…å½“ `--file_source bm25` æ—¶éœ€è¦
- ä½¿ç”¨ `oracle` æˆ– `all` æ—¶å¿½ç•¥æ­¤å‚æ•°

---

## 6ï¸âƒ£ `--prompt_style`

### ğŸ“– è¯´æ˜
é€‰æ‹© prompt çš„æ ¼å¼æ ·å¼

### ğŸ¯ ç±»å‹
`str`

### ğŸ’¡ é»˜è®¤å€¼
`"style-3"`

### âœ… å¯é€‰å€¼
- `style-2`
- `style-3` (æ¨è)
- `full_file_gen`
- `style-2-edits-only`

### ğŸ“ å„æ ·å¼å¯¹æ¯”

#### **style-2**
```
You will be provided with a partial code base and an issue statement...

<issue>
{problem_statement}
</issue>

<code>
{å®Œæ•´ä»£ç æ–‡ä»¶,å¸¦è¡Œå·}
</code>

I need you to solve this issue by generating a single patch file...

<patch>
{ç¤ºä¾‹ patch}
</patch>
```

#### **style-3** (æ¨è)
```
You will be provided with a partial code base and an issue statement...

<issue>
{problem_statement}
</issue>

<code>
{å®Œæ•´ä»£ç æ–‡ä»¶,å¸¦è¡Œå·}
</code>

Here is an example of a patch file. It consists of changes to the code base...

<patch>
{ç¤ºä¾‹ patch}
</patch>

I need you to solve the provided issue by generating a single patch file...
Respond below:
```

**åŒºåˆ«**: style-3 æ·»åŠ äº†å¯¹ patch æ ¼å¼çš„è§£é‡Šå’Œæ˜ç¡®çš„å“åº”æç¤º

#### **full_file_gen**
```
You will be provided with a partial code base and an issue statement...

<issue>
{problem_statement}
</issue>

<code>
{å®Œæ•´ä»£ç æ–‡ä»¶,ä¸å¸¦è¡Œå·}
</code>

I need you to solve this issue by regenerating the full files...

<example>
{å®Œæ•´æ–‡ä»¶ç¤ºä¾‹}
</example>
```

**ç‰¹ç‚¹**:
- è¦æ±‚æ¨¡å‹ç”Ÿæˆå®Œæ•´æ–‡ä»¶è€Œé patch
- ä»£ç ä¸å¸¦è¡Œå·
- é€‚åˆæŸäº›ç‰¹å®šåœºæ™¯

#### **style-2-edits-only**
```
{ä¸ style-2 ç›¸åŒ,ä½†åªæ˜¾ç¤ºéœ€è¦ç¼–è¾‘çš„ä»£ç ç‰‡æ®µ}

<code>
[start of file.py]
...
10 def function():
11     old_code
12     return value
...
[end of file.py]
</code>
```

**ç‰¹ç‚¹**:
- åªæ˜¾ç¤ºéœ€è¦ä¿®æ”¹çš„ä»£ç åŒºåŸŸ(å‰åå„ 15 è¡Œ)
- èŠ‚çœ token
- éœ€è¦é…åˆ oracle ä½¿ç”¨(å› ä¸ºéœ€è¦çŸ¥é“ä¿®æ”¹ä½ç½®)

### ğŸ’» ç¤ºä¾‹
```bash
# ä½¿ç”¨æ¨èçš„ style-3
--prompt_style style-3

# ä½¿ç”¨ full_file_gen ç”Ÿæˆå®Œæ•´æ–‡ä»¶
--prompt_style full_file_gen
```

---

## 7ï¸âƒ£ `--file_source`

### ğŸ“– è¯´æ˜
é€‰æ‹©å¦‚ä½•è·å–ç›¸å…³ä»£ç æ–‡ä»¶

### ğŸ¯ ç±»å‹
`str`

### ğŸ’¡ é»˜è®¤å€¼
`"oracle"`

### âœ… å¯é€‰å€¼
- `oracle`: ä»æ­£ç¡®ç­”æ¡ˆä¸­æå–æ–‡ä»¶
- `bm25`: ä½¿ç”¨ BM25 æ£€ç´¢
- `all`: åŒ…å«æ‰€æœ‰æ–‡ä»¶

### ğŸ“ è¯¦ç»†è¯´æ˜

#### **oracle** (é¢„è¨€æœºæ¨¡å¼)
```python
# ä»æ­£ç¡®çš„ patch ä¸­æå–è¢«ä¿®æ”¹çš„æ–‡ä»¶
patch = unidiff.PatchSet(instance["patch"])
files = {pf.source_file for pf in patch}
```

**ä¼˜ç‚¹**:
- âœ… æä¾›æœ€ç²¾ç¡®çš„ä»£ç ä¸Šä¸‹æ–‡
- âœ… ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€æ–‡ä»¶
- âœ… é€‚åˆç ”ç©¶æ¨¡å‹çš„ç†è®ºä¸Šç•Œ

**ç¼ºç‚¹**:
- âŒ éœ€è¦çŸ¥é“æ­£ç¡®ç­”æ¡ˆ
- âŒ å®é™…åº”ç”¨ä¸­ä¸å¯ç”¨

**ç”¨é€”**:
- è®­ç»ƒæ•°æ®ç”Ÿæˆ
- æ€§èƒ½ä¸Šç•Œæµ‹è¯•
- å¯¹æ¯”å®éªŒåŸºå‡†

#### **bm25** (æ£€ç´¢æ¨¡å¼)
```python
# ä½¿ç”¨ BM25 ç®—æ³•æ£€ç´¢æœ€ç›¸å…³çš„æ–‡ä»¶
hits = search(problem_statement, bm25_index)
files = [hit["docid"] for hit in hits[:k]]
```

**ä¼˜ç‚¹**:
- âœ… ä¸éœ€è¦çŸ¥é“ç­”æ¡ˆ
- âœ… æ¨¡æ‹ŸçœŸå®åœºæ™¯
- âœ… å¯é…ç½®æ£€ç´¢æ•°é‡

**ç¼ºç‚¹**:
- âŒ å¯èƒ½æ£€ç´¢åˆ°ä¸ç›¸å…³æ–‡ä»¶
- âŒ å¯èƒ½é—æ¼å…³é”®æ–‡ä»¶

**ç”¨é€”**:
- å®é™…æ¨ç†
- çœŸå®åœºæ™¯è¯„ä¼°

**éœ€è¦é…åˆ**:
- `--retrieval_file`: BM25 æ£€ç´¢ç»“æœ
- `--k`: Top-K æ–‡ä»¶æ•°é‡
- `--max_context_len`: token é™åˆ¶

#### **all** (å…¨é‡æ¨¡å¼)
```python
# åŒ…å«ä»“åº“ä¸­æ‰€æœ‰ä»£ç æ–‡ä»¶
files = ingest_directory_contents(repo_path)
```

**ä¼˜ç‚¹**:
- âœ… åŒ…å«æ‰€æœ‰ä¿¡æ¯
- âœ… ä¸ä¼šé—æ¼æ–‡ä»¶

**ç¼ºç‚¹**:
- âŒ token æ¶ˆè€—å·¨å¤§
- âŒ å¤§å¤šæ•°æ–‡ä»¶æ— å…³
- âŒ è¶…è¿‡æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶

**ç”¨é€”**:
- æµ‹è¯•é•¿ä¸Šä¸‹æ–‡æ¨¡å‹
- ç‰¹æ®Šç ”ç©¶åœºæ™¯

### ğŸ’» ç¤ºä¾‹
```bash
# Oracle æ¨¡å¼(ç ”ç©¶ç”¨)
--file_source oracle

# BM25 æ¨¡å¼(å®é™…åº”ç”¨)
--file_source bm25 \
--retrieval_file ./bm25_results.jsonl \
--k 10 \
--max_context_len 16000

# å…¨é‡æ¨¡å¼(æµ‹è¯•é•¿ä¸Šä¸‹æ–‡)
--file_source all
```

---

## 8ï¸âƒ£ `--k`

### ğŸ“– è¯´æ˜
ä½¿ç”¨ BM25 æ£€ç´¢æ—¶,æœ€å¤šåŒ…å«å¤šå°‘ä¸ªæ–‡ä»¶

### ğŸ¯ ç±»å‹
`int`

### ğŸ’¡ é»˜è®¤å€¼
`None`

### ğŸ“ ç”¨é€”
é™åˆ¶æ£€ç´¢æ–‡ä»¶çš„æ•°é‡,é¿å… token æ¶ˆè€—è¿‡å¤§

### ğŸ’» ç¤ºä¾‹
```bash
# åŒ…å« Top-10 æœ€ç›¸å…³çš„æ–‡ä»¶
--k 10

# åŒ…å« Top-20 æœ€ç›¸å…³çš„æ–‡ä»¶
--k 20

# ä¸é™åˆ¶æ•°é‡(å— max_context_len çº¦æŸ)
# (ä¸æŒ‡å®š --k)
```

### ğŸ“Œ å·¥ä½œåŸç†
```python
# æŒ‰ç›¸å…³æ€§æ’åº,å–å‰ k ä¸ª
hits = retrieval_results[:k]
for hit in hits:
    file_contents[hit["docid"]] = read_file(hit["docid"])
```

### âš ï¸ æ³¨æ„
- ä»…å½“ `--file_source bm25` æ—¶ç”Ÿæ•ˆ
- å¦‚æœåŒæ—¶æŒ‡å®š `--max_context_len`,ä¼šåœ¨ token é™åˆ¶å’Œæ–‡ä»¶æ•°é‡é™åˆ¶ä¸­å–è¾ƒå°å€¼
- ä½¿ç”¨ `oracle` æˆ– `all` æ—¶å¿½ç•¥æ­¤å‚æ•°

---

## 9ï¸âƒ£ `--max_context_len`

### ğŸ“– è¯´æ˜
é™åˆ¶ prompt çš„æœ€å¤§ token æ•°é‡

### ğŸ¯ ç±»å‹
`int`

### ğŸ’¡ é»˜è®¤å€¼
`None` (ä¸é™åˆ¶)

### ğŸ“ ç”¨é€”
ç¡®ä¿ç”Ÿæˆçš„ prompt ä¸è¶…è¿‡æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£

### ğŸ’» ç¤ºä¾‹
```bash
# GPT-3.5 (4K ä¸Šä¸‹æ–‡)
--max_context_len 4000

# GPT-4 (8K ä¸Šä¸‹æ–‡)
--max_context_len 8000

# GPT-4-32K
--max_context_len 32000

# Claude-2 (100K ä¸Šä¸‹æ–‡)
--max_context_len 100000
```

### ğŸ“Œ å·¥ä½œåŸç†
```python
# 1. è®¡ç®—åŸºç¡€ prompt çš„ token æ•°
base_tokens = tokenizer(base_prompt)

# 2. é€ä¸ªæ·»åŠ æ–‡ä»¶,ç›´åˆ°è¾¾åˆ°ä¸Šé™
current_tokens = base_tokens
for file in retrieved_files:
    file_tokens = tokenizer(file_content)
    if current_tokens + file_tokens < max_context_len:
        include_files.append(file)
        current_tokens += file_tokens
    else:
        break  # è¾¾åˆ°ä¸Šé™,åœæ­¢æ·»åŠ 
```

### ğŸ“Š å¸¸ç”¨é…ç½®

| æ¨¡å‹ | ä¸Šä¸‹æ–‡çª—å£ | æ¨èè®¾ç½® | å¤‡æ³¨ |
|------|-----------|---------|------|
| GPT-3.5-turbo | 4K | 3500 | ç•™å‡º 500 ç»™è¾“å‡º |
| GPT-3.5-turbo-16k | 16K | 15000 | ç•™å‡º 1000 ç»™è¾“å‡º |
| GPT-4 | 8K | 7500 | ç•™å‡º 500 ç»™è¾“å‡º |
| GPT-4-32K | 32K | 30000 | ç•™å‡º 2000 ç»™è¾“å‡º |
| GPT-4-turbo | 128K | 120000 | ç•™å‡º 8000 ç»™è¾“å‡º |
| Claude-2 | 100K | 95000 | ç•™å‡º 5000 ç»™è¾“å‡º |
| Claude-3 | 200K | 190000 | ç•™å‡º 10000 ç»™è¾“å‡º |

### âš ï¸ æ³¨æ„
- å¿…é¡»é…åˆ `--tokenizer_name` ä½¿ç”¨
- ä¸èƒ½ä¸ `--file_source oracle` æˆ– `all` åŒæ—¶ä½¿ç”¨
- åªå¯¹ `bm25` æ¨¡å¼æœ‰æ•ˆ

---

## ğŸ”Ÿ `--tokenizer_name`

### ğŸ“– è¯´æ˜
æŒ‡å®šç”¨äºè®¡ç®— token æ•°é‡çš„åˆ†è¯å™¨

### ğŸ¯ ç±»å‹
`str`

### ğŸ’¡ é»˜è®¤å€¼
`None`

### âœ… å¯é€‰å€¼
- `cl100k`: OpenAI GPT-3.5/GPT-4 ä½¿ç”¨çš„åˆ†è¯å™¨
- `llama`: LLaMA ç³»åˆ—æ¨¡å‹çš„åˆ†è¯å™¨

### ğŸ“ è¯¦ç»†è¯´æ˜

#### **cl100k**
```python
import tiktoken
tokenizer = tiktoken.get_encoding("cl100k_base")
tokens = tokenizer.encode(text)
```

**é€‚ç”¨æ¨¡å‹**:
- GPT-3.5-turbo ç³»åˆ—
- GPT-4 ç³»åˆ—
- text-embedding-ada-002

**ç‰¹ç‚¹**:
- è¯æ±‡è¡¨å¤§å°: 100,000
- é«˜æ•ˆçš„å¤šè¯­è¨€æ”¯æŒ
- ä¸æ”¯æŒå¤šè¿›ç¨‹(è‡ªåŠ¨ä½¿ç”¨å•è¿›ç¨‹)

#### **llama**
```python
from transformers import LlamaTokenizer
tokenizer = LlamaTokenizer.from_pretrained("togethercomputer/LLaMA-2-7B-32K")
tokens = tokenizer(text)["input_ids"]
```

**é€‚ç”¨æ¨¡å‹**:
- LLaMA ç³»åˆ—
- SWE-Llama
- LLaMA-2

**ç‰¹ç‚¹**:
- è¯æ±‡è¡¨å¤§å°: 32,000
- æ”¯æŒå¤šè¿›ç¨‹
- éœ€è¦ GPU ç¯å¢ƒ

### ğŸ’» ç¤ºä¾‹
```bash
# ä½¿ç”¨ GPT-4
--tokenizer_name cl100k \
--max_context_len 8000

# ä½¿ç”¨ LLaMA
--tokenizer_name llama \
--max_context_len 16000
```

### âš ï¸ æ³¨æ„
- ä»…å½“æŒ‡å®š `--max_context_len` æ—¶éœ€è¦
- é€‰æ‹©ä¸ç›®æ ‡æ¨¡å‹åŒ¹é…çš„åˆ†è¯å™¨
- cl100k ä¸æ”¯æŒå¤šè¿›ç¨‹,ä¼šè‡ªåŠ¨é™ä¸ºå•è¿›ç¨‹

---

## 1ï¸âƒ£1ï¸âƒ£ `--push_to_hub_user`

### ğŸ“– è¯´æ˜
å°†ç”Ÿæˆçš„æ•°æ®é›†æ¨é€åˆ° HuggingFace Hub

### ğŸ¯ ç±»å‹
`str`

### ğŸ’¡ é»˜è®¤å€¼
`None` (ä¿å­˜åˆ°æœ¬åœ°)

### ğŸ“ ç”¨é€”
ç›´æ¥å°†æ•°æ®é›†ä¸Šä¼ åˆ° HuggingFace,ä¾¿äºåˆ†äº«å’Œä½¿ç”¨

### ğŸ’» ç¤ºä¾‹
```bash
# æ¨é€åˆ° HuggingFace Hub
export HUGGING_FACE_HUB_TOKEN="hf_xxxxxxxxxxxx"

python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench \
    --file_source bm25 \
    --retrieval_file ./bm25_results.jsonl \
    --k 10 \
    --prompt_style style-3 \
    --push_to_hub_user your-username

# ç”Ÿæˆçš„æ•°æ®é›†ä¼šä¸Šä¼ åˆ°:
# https://huggingface.co/datasets/your-username/SWE-bench__style-3__fs-bm25__k-10
```

### ğŸ“Œ å‰ç½®æ¡ä»¶
```bash
# 1. å®‰è£… HuggingFace Hub
pip install huggingface-hub

# 2. ç™»å½• HuggingFace
huggingface-cli login

# æˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡
export HUGGING_FACE_HUB_TOKEN="hf_your_token_here"
```

### âš ï¸ æ³¨æ„
- å¿…é¡»è®¾ç½® `HUGGING_FACE_HUB_TOKEN` ç¯å¢ƒå˜é‡
- ä¸èƒ½åŒæ—¶æŒ‡å®š `--output_dir`
- æ•°æ®é›†ä¼šè‡ªåŠ¨å‘½å

---

## ğŸ“Š å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: åˆ›å»º Oracle æ•°æ®é›†(ç ”ç©¶ç”¨)
```bash
python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench_Lite \
    --splits test \
    --file_source oracle \
    --prompt_style style-3 \
    --output_dir ./datasets/oracle
```

### ç¤ºä¾‹ 2: åˆ›å»º BM25 æ£€ç´¢æ•°æ®é›†(å®é™…åº”ç”¨)
```bash
# æ­¥éª¤ 1: è¿è¡Œ BM25 æ£€ç´¢
python -m swebench.inference.make_datasets.bm25_retrieval \
    --dataset_name princeton-nlp/SWE-bench_Lite \
    --output_file ./bm25_lite.jsonl

# æ­¥éª¤ 2: åˆ›å»ºæ•°æ®é›†
python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench_Lite \
    --splits test \
    --file_source bm25 \
    --retrieval_file ./bm25_lite.jsonl \
    --k 10 \
    --max_context_len 16000 \
    --tokenizer_name cl100k \
    --prompt_style style-3 \
    --output_dir ./datasets/bm25_16k
```

### ç¤ºä¾‹ 3: åˆ›å»ºè®­ç»ƒæ•°æ®é›†å¹¶æ¨é€åˆ° Hub
```bash
export HUGGING_FACE_HUB_TOKEN="hf_xxxxxxxxxxxx"

python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench \
    --splits train test \
    --validation_ratio 0.05 \
    --file_source oracle \
    --prompt_style style-3 \
    --push_to_hub_user my-username
```

### ç¤ºä¾‹ 4: å¤šç§é…ç½®å¯¹æ¯”
```bash
# é…ç½® A: Oracle + style-3
python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench_Lite \
    --file_source oracle \
    --prompt_style style-3 \
    --output_dir ./configs/oracle_style3

# é…ç½® B: BM25 (k=5) + style-2
python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench_Lite \
    --file_source bm25 \
    --retrieval_file ./bm25_lite.jsonl \
    --k 5 \
    --prompt_style style-2 \
    --output_dir ./configs/bm25_k5_style2

# é…ç½® C: BM25 (tokené™åˆ¶) + full_file_gen
python -m swebench.inference.make_datasets.create_text_dataset \
    --dataset_name_or_path princeton-nlp/SWE-bench_Lite \
    --file_source bm25 \
    --retrieval_file ./bm25_lite.jsonl \
    --max_context_len 32000 \
    --tokenizer_name cl100k \
    --prompt_style full_file_gen \
    --output_dir ./configs/bm25_32k_fullgen
```

---

## ğŸ¯ å‚æ•°ç»„åˆå»ºè®®

### åœºæ™¯ 1: å¿«é€Ÿæµ‹è¯•
```bash
--dataset_name_or_path princeton-nlp/SWE-bench_Lite \
--splits test \
--file_source oracle \
--prompt_style style-3 \
--output_dir ./quick_test
```

### åœºæ™¯ 2: è®­ç»ƒæ¨¡å‹
```bash
--dataset_name_or_path princeton-nlp/SWE-bench \
--splits train \
--validation_ratio 0.05 \
--file_source oracle \
--prompt_style style-3 \
--output_dir ./training_data
```

### åœºæ™¯ 3: çœŸå®æ¨ç†è¯„ä¼°
```bash
--dataset_name_or_path princeton-nlp/SWE-bench \
--splits test \
--file_source bm25 \
--retrieval_file ./bm25_results.jsonl \
--k 10 \
--max_context_len 16000 \
--tokenizer_name cl100k \
--prompt_style style-3 \
--output_dir ./eval_data
```

### åœºæ™¯ 4: é•¿ä¸Šä¸‹æ–‡æ¨¡å‹
```bash
--dataset_name_or_path princeton-nlp/SWE-bench \
--splits test \
--file_source bm25 \
--retrieval_file ./bm25_results.jsonl \
--max_context_len 100000 \
--tokenizer_name cl100k \
--prompt_style style-3 \
--output_dir ./long_context_data
```

---

## âš ï¸ å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### é”™è¯¯ 1: `Cannot use max_context_len with oracle`
```bash
# âŒ é”™è¯¯
--file_source oracle --max_context_len 16000

# âœ… æ­£ç¡®
--file_source bm25 --max_context_len 16000
```

### é”™è¯¯ 2: `Must specify tokenizer_name if using max_context_len`
```bash
# âŒ é”™è¯¯
--max_context_len 16000

# âœ… æ­£ç¡®
--max_context_len 16000 --tokenizer_name cl100k
```

### é”™è¯¯ 3: `retrieval_file not found`
```bash
# å…ˆç”Ÿæˆæ£€ç´¢ç»“æœ
python -m swebench.inference.make_datasets.bm25_retrieval \
    --dataset_name princeton-nlp/SWE-bench \
    --output_file ./bm25_results.jsonl

# ç„¶åä½¿ç”¨
--retrieval_file ./bm25_results.jsonl
```

### é”™è¯¯ 4: `Cannot provide output_dir if pushing to the Hub`
```bash
# âŒ é”™è¯¯
--push_to_hub_user my-user --output_dir ./data

# âœ… æ­£ç¡®(äºŒé€‰ä¸€)
--push_to_hub_user my-user  # æ¨é€åˆ° Hub
--output_dir ./data         # ä¿å­˜åˆ°æœ¬åœ°
```

---

## ğŸ“š å‚è€ƒèµ„æº

- [SWE-bench å®˜æ–¹æ–‡æ¡£](https://swebench.com)
- [HuggingFace Datasets æ–‡æ¡£](https://huggingface.co/docs/datasets)
- [Tiktoken æ–‡æ¡£](https://github.com/openai/tiktoken)
- [BM25 æ£€ç´¢æ–‡æ¡£](./bm25_retrieval.md)

---

**æœ€åæ›´æ–°**: 2025-10-06
**ç»´æŠ¤è€…**: SWE-bench Team
