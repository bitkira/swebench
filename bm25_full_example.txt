================================================================================
BM25 数据集示例 - 完整提示词
================================================================================

Instance ID: astropy__astropy-12907
Repo: astropy/astropy
Text Length: 98821 字符

================================================================================
完整的 text 字段内容（这就是发送给模型的提示词）:
================================================================================

You will be provided with a partial code base and an issue statement explaining a problem to resolve.
<issue>
Modeling's `separability_matrix` does not compute separability correctly for nested CompoundModels
Consider the following model:

```python
from astropy.modeling import models as m
from astropy.modeling.separable import separability_matrix

cm = m.Linear1D(10) & m.Linear1D(5)
```

It's separability matrix as you might expect is a diagonal:

```python
>>> separability_matrix(cm)
array([[ True, False],
       [False,  True]])
```

If I make the model more complex:
```python
>>> separability_matrix(m.Pix2Sky_TAN() & m.Linear1D(10) & m.Linear1D(5))
array([[ True,  True, False, False],
       [ True,  True, False, False],
       [False, False,  True, False],
       [False, False, False,  True]])
```

The output matrix is again, as expected, the outputs and inputs to the linear models are separable and independent of each other.

If however, I nest these compound models:
```python
>>> separability_matrix(m.Pix2Sky_TAN() & cm)
array([[ True,  True, False, False],
       [ True,  True, False, False],
       [False, False,  True,  True],
       [False, False,  True,  True]])
```
Suddenly the inputs and outputs are no longer separable?

This feels like a bug to me, but I might be missing something?

</issue>
<code>
[start of README.rst]
1 =======
2 Astropy
3 =======
4 
5 |Actions Status| |CircleCI Status| |Azure Status| |Coverage Status| |PyPI Status| |Documentation Status| |Zenodo|
6 
7 The Astropy Project (http://astropy.org/) is a community effort to develop a
8 single core package for Astronomy in Python and foster interoperability between
9 Python astronomy packages. This repository contains the core package which is
10 intended to contain much of the core functionality and some common tools needed
11 for performing astronomy and astrophysics with Python.
12 
13 Releases are `registered on PyPI <https://pypi.org/project/astropy>`_,
14 and development is occurring at the
15 `project's GitHub page <http://github.com/astropy/astropy>`_.
16 
17 For installation instructions, see the `online documentation <https://docs.astropy.org/>`_
18 or  `docs/install.rst <docs/install.rst>`_ in this source distribution.
19 
20 Contributing Code, Documentation, or Feedback
21 ---------------------------------------------
22 
23 The Astropy Project is made both by and for its users, so we welcome and
24 encourage contributions of many kinds. Our goal is to keep this a positive,
25 inclusive, successful, and growing community by abiding with the
26 `Astropy Community Code of Conduct <http://www.astropy.org/about.html#codeofconduct>`_.
27 
28 More detailed information on contributing to the project or submitting feedback
29 can be found on the `contributions <http://www.astropy.org/contribute.html>`_
30 page. A `summary of contribution guidelines <CONTRIBUTING.md>`_ can also be
31 used as a quick reference when you are ready to start writing or validating
32 code for submission.
33 
34 Supporting the Project
35 ----------------------
36 
37 |NumFOCUS| |Donate|
38 
39 The Astropy Project is sponsored by NumFOCUS, a 501(c)(3) nonprofit in the
40 United States. You can donate to the project by using the link above, and this
41 donation will support our mission to promote sustainable, high-level code base
42 for the astronomy community, open code development, educational materials, and
43 reproducible scientific research.
44 
45 License
46 -------
47 
48 Astropy is licensed under a 3-clause BSD style license - see the
49 `LICENSE.rst <LICENSE.rst>`_ file.
50 
51 .. |Actions Status| image:: https://github.com/astropy/astropy/workflows/CI/badge.svg
52     :target: https://github.com/astropy/astropy/actions
53     :alt: Astropy's GitHub Actions CI Status
54 
55 .. |CircleCI Status| image::  https://img.shields.io/circleci/build/github/astropy/astropy/main?logo=circleci&label=CircleCI
56     :target: https://circleci.com/gh/astropy/astropy
57     :alt: Astropy's CircleCI Status
58 
59 .. |Azure Status| image:: https://dev.azure.com/astropy-project/astropy/_apis/build/status/astropy.astropy?repoName=astropy%2Fastropy&branchName=main
60     :target: https://dev.azure.com/astropy-project/astropy
61     :alt: Astropy's Azure Pipelines Status
62 
63 .. |Coverage Status| image:: https://codecov.io/gh/astropy/astropy/branch/main/graph/badge.svg
64     :target: https://codecov.io/gh/astropy/astropy
65     :alt: Astropy's Coverage Status
66 
67 .. |PyPI Status| image:: https://img.shields.io/pypi/v/astropy.svg
68     :target: https://pypi.org/project/astropy
69     :alt: Astropy's PyPI Status
70 
71 .. |Zenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.4670728.svg
72    :target: https://doi.org/10.5281/zenodo.4670728
73    :alt: Zenodo DOI
74 
75 .. |Documentation Status| image:: https://img.shields.io/readthedocs/astropy/latest.svg?logo=read%20the%20docs&logoColor=white&label=Docs&version=stable
76     :target: https://docs.astropy.org/en/stable/?badge=stable
77     :alt: Documentation Status
78 
79 .. |NumFOCUS| image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A
80     :target: http://numfocus.org
81     :alt: Powered by NumFOCUS
82 
83 .. |Donate| image:: https://img.shields.io/badge/Donate-to%20Astropy-brightgreen.svg
84     :target: https://numfocus.salsalabs.org/donate-to-astropy/index.html
85 
86 
87 If you locally cloned this repo before 7 Apr 2021
88 -------------------------------------------------
89 
90 The primary branch for this repo has been transitioned from ``master`` to
91 ``main``.  If you have a local clone of this repository and want to keep your
92 local branch in sync with this repo, you'll need to do the following in your
93 local clone from your terminal::
94 
95    git fetch --all --prune
96    # you can stop here if you don't use your local "master"/"main" branch
97    git branch -m master main
98    git branch -u origin/main main
99 
100 If you are using a GUI to manage your repos you'll have to find the equivalent
101 commands as it's different for different programs. Alternatively, you can just
102 delete your local clone and re-clone!
103 
[end of README.rst]
[start of astropy/modeling/fitting.py]
1 # Licensed under a 3-clause BSD style license - see LICENSE.rst
2 
3 """
4 This module implements classes (called Fitters) which combine optimization
5 algorithms (typically from `scipy.optimize`) with statistic functions to perform
6 fitting. Fitters are implemented as callable classes. In addition to the data
7 to fit, the ``__call__`` method takes an instance of
8 `~astropy.modeling.core.FittableModel` as input, and returns a copy of the
9 model with its parameters determined by the optimizer.
10 
11 Optimization algorithms, called "optimizers" are implemented in
12 `~astropy.modeling.optimizers` and statistic functions are in
13 `~astropy.modeling.statistic`. The goal is to provide an easy to extend
14 framework and allow users to easily create new fitters by combining statistics
15 with optimizers.
16 
17 There are two exceptions to the above scheme.
18 `~astropy.modeling.fitting.LinearLSQFitter` uses Numpy's `~numpy.linalg.lstsq`
19 function.  `~astropy.modeling.fitting.LevMarLSQFitter` uses
20 `~scipy.optimize.leastsq` which combines optimization and statistic in one
21 implementation.
22 """
23 # pylint: disable=invalid-name
24 
25 import abc
26 import inspect
27 import operator
28 import warnings
29 from importlib.metadata import entry_points
30 
31 from functools import reduce, wraps
32 
33 import numpy as np
34 
35 from astropy.units import Quantity
36 from astropy.utils.exceptions import AstropyUserWarning
37 from astropy.utils.decorators import deprecated
38 from .utils import poly_map_domain, _combine_equivalency_dict
39 from .optimizers import (SLSQP, Simplex)
40 from .statistic import (leastsquare)
41 from .optimizers import (DEFAULT_MAXITER, DEFAULT_EPS, DEFAULT_ACC)
42 from .spline import (SplineInterpolateFitter, SplineSmoothingFitter,
43                      SplineExactKnotsFitter, SplineSplrepFitter)
44 
45 __all__ = ['LinearLSQFitter', 'LevMarLSQFitter', 'FittingWithOutlierRemoval',
46            'SLSQPLSQFitter', 'SimplexLSQFitter', 'JointFitter', 'Fitter',
47            "ModelLinearityError", "ModelsError"]
48 
49 
50 # Statistic functions implemented in `astropy.modeling.statistic.py
51 STATISTICS = [leastsquare]
52 
53 # Optimizers implemented in `astropy.modeling.optimizers.py
54 OPTIMIZERS = [Simplex, SLSQP]
55 
56 
57 class Covariance():
58     """Class for covariance matrix calculated by fitter. """
59 
60     def __init__(self, cov_matrix, param_names):
61         self.cov_matrix = cov_matrix
62         self.param_names = param_names
63 
64     def pprint(self, max_lines, round_val):
65         # Print and label lower triangle of covariance matrix
66         # Print rows for params up to `max_lines`, round floats to 'round_val'
67         longest_name = max([len(x) for x in self.param_names])
68         ret_str = 'parameter variances / covariances \n'
69         fstring = f'{"": <{longest_name}}| {{0}}\n'
70         for i, row in enumerate(self.cov_matrix):
71             if i <= max_lines-1:
72                 param = self.param_names[i]
73                 ret_str += fstring.replace(' '*len(param), param, 1).\
74                            format(repr(np.round(row[:i+1], round_val))[7:-2])
75             else:
76                 ret_str += '...'
77         return(ret_str.rstrip())
78 
79     def __repr__(self):
80         return(self.pprint(max_lines=10, round_val=3))
81 
82     def __getitem__(self, params):
83         # index covariance matrix by parameter names or indices
84         if len(params) != 2:
85             raise ValueError('Covariance must be indexed by two values.')
86         if all(isinstance(item, str) for item in params):
87             i1, i2 = self.param_names.index(params[0]), self.param_names.index(params[1])
88         elif all(isinstance(item, int) for item in params):
89             i1, i2 = params
90         else:
91             raise TypeError('Covariance can be indexed by two parameter names or integer indices.')
92         return(self.cov_matrix[i1][i2])
93 
94 
95 class StandardDeviations():
96     """ Class for fitting uncertainties."""
97 
98     def __init__(self, cov_matrix, param_names):
99         self.param_names = param_names
100         self.stds = self._calc_stds(cov_matrix)
101 
102     def _calc_stds(self, cov_matrix):
103         # sometimes scipy lstsq returns a non-sensical negative vals in the
104         # diagonals of the cov_x it computes.
105         stds = [np.sqrt(x) if x > 0 else None for x in np.diag(cov_matrix)]
106         return stds
107 
108     def pprint(self, max_lines, round_val):
109         longest_name = max([len(x) for x in self.param_names])
110         ret_str = 'standard deviations\n'
111         fstring = '{0}{1}| {2}\n'
112         for i, std in enumerate(self.stds):
113             if i <= max_lines-1:
114                 param = self.param_names[i]
115                 ret_str += fstring.format(param,
116                                           ' ' * (longest_name - len(param)),
117                                           str(np.round(std, round_val)))
118             else:
119                 ret_str += '...'
120         return(ret_str.rstrip())
121 
122     def __repr__(self):
123         return(self.pprint(max_lines=10, round_val=3))
124 
125     def __getitem__(self, param):
126         if isinstance(param, str):
127             i = self.param_names.index(param)
128         elif isinstance(param, int):
129             i = param
130         else:
131             raise TypeError('Standard deviation can be indexed by parameter name or integer.')
132         return(self.stds[i])
133 
134 
135 class ModelsError(Exception):
136     """Base class for model exceptions"""
137 
138 
139 class ModelLinearityError(ModelsError):
140     """ Raised when a non-linear model is passed to a linear fitter."""
141 
142 
143 class UnsupportedConstraintError(ModelsError, ValueError):
144     """
145     Raised when a fitter does not support a type of constraint.
146     """
147 
148 
149 class _FitterMeta(abc.ABCMeta):
150     """
151     Currently just provides a registry for all Fitter classes.
152     """
153 
154     registry = set()
155 
156     def __new__(mcls, name, bases, members):
157         cls = super().__new__(mcls, name, bases, members)
158 
159         if not inspect.isabstract(cls) and not name.startswith('_'):
160             mcls.registry.add(cls)
161 
162         return cls
163 
164 
165 def fitter_unit_support(func):
166     """
167     This is a decorator that can be used to add support for dealing with
168     quantities to any __call__ method on a fitter which may not support
169     quantities itself. This is done by temporarily removing units from all
170     parameters then adding them back once the fitting has completed.
171     """
172     @wraps(func)
173     def wrapper(self, model, x, y, z=None, **kwargs):
174         equivalencies = kwargs.pop('equivalencies', None)
175 
176         data_has_units = (isinstance(x, Quantity) or
177                           isinstance(y, Quantity) or
178                           isinstance(z, Quantity))
179 
180         model_has_units = model._has_units
181 
182         if data_has_units or model_has_units:
183 
184             if model._supports_unit_fitting:
185 
186                 # We now combine any instance-level input equivalencies with user
187                 # specified ones at call-time.
188 
189                 input_units_equivalencies = _combine_equivalency_dict(
190                     model.inputs, equivalencies, model.input_units_equivalencies)
191 
192                 # If input_units is defined, we transform the input data into those
193                 # expected by the model. We hard-code the input names 'x', and 'y'
194                 # here since FittableModel instances have input names ('x',) or
195                 # ('x', 'y')
196 
197                 if model.input_units is not None:
198                     if isinstance(x, Quantity):
199                         x = x.to(model.input_units[model.inputs[0]],
200                                  equivalencies=input_units_equivalencies[model.inputs[0]])
201                     if isinstance(y, Quantity) and z is not None:
202                         y = y.to(model.input_units[model.inputs[1]],
203                                  equivalencies=input_units_equivalencies[model.inputs[1]])
204 
205                 # Create a dictionary mapping the real model inputs and outputs
206                 # names to the data. This remapping of names must be done here, after
207                 # the input data is converted to the correct units.
208                 rename_data = {model.inputs[0]: x}
209                 if z is not None:
210                     rename_data[model.outputs[0]] = z
211                     rename_data[model.inputs[1]] = y
212                 else:
213                     rename_data[model.outputs[0]] = y
214                     rename_data['z'] = None
215 
216                 # We now strip away the units from the parameters, taking care to
217                 # first convert any parameters to the units that correspond to the
218                 # input units (to make sure that initial guesses on the parameters)
219                 # are in the right unit system
220                 model = model.without_units_for_data(**rename_data)
221                 if isinstance(model, tuple):
222                     rename_data['_left_kwargs'] = model[1]
223                     rename_data['_right_kwargs'] = model[2]
224                     model = model[0]
225 
226                 # We strip away the units from the input itself
227                 add_back_units = False
228 
229                 if isinstance(x, Quantity):
230                     add_back_units = True
231                     xdata = x.value
232                 else:
233                     xdata = np.asarray(x)
234 
235                 if isinstance(y, Quantity):
236                     add_back_units = True
237                     ydata = y.value
238                 else:
239                     ydata = np.asarray(y)
240 
241                 if z is not None:
242                     if isinstance(z, Quantity):
243                         add_back_units = True
244                         zdata = z.value
245                     else:
246                         zdata = np.asarray(z)
247                 # We run the fitting
248                 if z is None:
249                     model_new = func(self, model, xdata, ydata, **kwargs)
250                 else:
251                     model_new = func(self, model, xdata, ydata, zdata, **kwargs)
252 
253                 # And finally we add back units to the parameters
254                 if add_back_units:
255                     model_new = model_new.with_units_from_data(**rename_data)
256                 return model_new
257 
258             else:
259 
260                 raise NotImplementedError("This model does not support being "
261                                           "fit to data with units.")
262 
263         else:
264 
265             return func(self, model, x, y, z=z, **kwargs)
266 
267     return wrapper
268 
269 
270 class Fitter(metaclass=_FitterMeta):
271     """
272     Base class for all fitters.
273 
274     Parameters
275     ----------
276     optimizer : callable
277         A callable implementing an optimization algorithm
278     statistic : callable
279         Statistic function
280 
281     """
282 
283     supported_constraints = []
284 
285     def __init__(self, optimizer, statistic):
286         if optimizer is None:
287             raise ValueError("Expected an optimizer.")
288         if statistic is None:
289             raise ValueError("Expected a statistic function.")
290         if inspect.isclass(optimizer):
291             # a callable class
292             self._opt_method = optimizer()
293         elif inspect.isfunction(optimizer):
294             self._opt_method = optimizer
295         else:
296             raise ValueError("Expected optimizer to be a callable class or a function.")
297         if inspect.isclass(statistic):
298             self._stat_method = statistic()
299         else:
300             self._stat_method = statistic
301 
302     def objective_function(self, fps, *args):
303         """
304         Function to minimize.
305 
306         Parameters
307         ----------
308         fps : list
309             parameters returned by the fitter
310         args : list
311             [model, [other_args], [input coordinates]]
312             other_args may include weights or any other quantities specific for
313             a statistic
314 
315         Notes
316         -----
317         The list of arguments (args) is set in the `__call__` method.
318         Fitters may overwrite this method, e.g. when statistic functions
319         require other arguments.
320 
321         """
322         model = args[0]
323         meas = args[-1]
324         fitter_to_model_params(model, fps)
325         res = self._stat_method(meas, model, *args[1:-1])
326         return res
327 
328     @staticmethod
329     def _add_fitting_uncertainties(*args):
330         """
331         When available, calculate and sets the parameter covariance matrix
332         (model.cov_matrix) and standard deviations (model.stds).
333         """
334         return None
335 
336     @abc.abstractmethod
337     def __call__(self):
338         """
339         This method performs the actual fitting and modifies the parameter list
340         of a model.
341         Fitter subclasses should implement this method.
342         """
343 
344         raise NotImplementedError("Subclasses should implement this method.")
345 
346 
347 # TODO: I have ongoing branch elsewhere that's refactoring this module so that
348 # all the fitter classes in here are Fitter subclasses.  In the meantime we
349 # need to specify that _FitterMeta is its metaclass.
350 class LinearLSQFitter(metaclass=_FitterMeta):
351     """
352     A class performing a linear least square fitting.
353     Uses `numpy.linalg.lstsq` to do the fitting.
354     Given a model and data, fits the model to the data and changes the
355     model's parameters. Keeps a dictionary of auxiliary fitting information.
356     Notes
357     -----
358     Note that currently LinearLSQFitter does not support compound models.
359     """
360 
361     supported_constraints = ['fixed']
362     supports_masked_input = True
363 
364     def __init__(self, calc_uncertainties=False):
365         self.fit_info = {'residuals': None,
366                          'rank': None,
367                          'singular_values': None,
368                          'params': None
369                          }
370         self._calc_uncertainties=calc_uncertainties
371 
372     @staticmethod
373     def _is_invertible(m):
374         """Check if inverse of matrix can be obtained."""
375         if m.shape[0] != m.shape[1]:
376             return False
377         if np.linalg.matrix_rank(m) < m.shape[0]:
378             return False
379         return True
380 
381     def _add_fitting_uncertainties(self, model, a, n_coeff, x, y, z=None,
382                                    resids=None):
383         """
384         Calculate and parameter covariance matrix and standard deviations
385         and set `cov_matrix` and `stds` attributes.
386         """
387         x_dot_x_prime = np.dot(a.T, a)
388         masked = False or hasattr(y, 'mask')
389 
390         # check if invertible. if not, can't calc covariance.
391         if not self._is_invertible(x_dot_x_prime):
392             return(model)
393         inv_x_dot_x_prime = np.linalg.inv(x_dot_x_prime)
394 
395         if z is None:  # 1D models
396             if len(model) == 1:  # single model
397                 mask = None
398                 if masked:
399                     mask = y.mask
400                 xx = np.ma.array(x, mask=mask)
401                 RSS = [(1/(xx.count()-n_coeff)) * resids]
402 
403             if len(model) > 1:  # model sets
404                 RSS = []   # collect sum residuals squared for each model in set
405                 for j in range(len(model)):
406                     mask = None
407                     if masked:
408                         mask = y.mask[..., j].flatten()
409                     xx = np.ma.array(x, mask=mask)
410                     eval_y = model(xx, model_set_axis=False)
411                     eval_y = np.rollaxis(eval_y, model.model_set_axis)[j]
412                     RSS.append((1/(xx.count()-n_coeff)) * np.sum((y[..., j] - eval_y)**2))
413 
414         else:  # 2D model
415             if len(model) == 1:
416                 mask = None
417                 if masked:
418                     warnings.warn('Calculation of fitting uncertainties '
419                                   'for 2D models with masked values not '
420                                   'currently supported.\n',
421                                   AstropyUserWarning)
422                     return
423                 xx, yy = np.ma.array(x, mask=mask), np.ma.array(y, mask=mask)
424                 # len(xx) instead of xx.count. this will break if values are masked?
425                 RSS = [(1/(len(xx)-n_coeff)) * resids]
426             else:
427                 RSS = []
428                 for j in range(len(model)):
429                     eval_z = model(x, y, model_set_axis=False)
430                     mask = None  # need to figure out how to deal w/ masking here.
431                     if model.model_set_axis == 1:
432                         # model_set_axis passed when evaluating only refers to input shapes
433                         # so output must be reshaped for model_set_axis=1.
434                         eval_z = np.rollaxis(eval_z, 1)
435                     eval_z = eval_z[j]
436                     RSS.append([(1/(len(x)-n_coeff)) * np.sum((z[j] - eval_z)**2)])
437 
438         covs = [inv_x_dot_x_prime * r for r in RSS]
439         free_param_names = [x for x in model.fixed if (model.fixed[x] is False)
440                             and (model.tied[x] is False)]
441 
442         if len(covs) == 1:
443             model.cov_matrix = Covariance(covs[0], model.param_names)
444             model.stds = StandardDeviations(covs[0], free_param_names)
445         else:
446             model.cov_matrix = [Covariance(cov, model.param_names) for cov in covs]
447             model.stds = [StandardDeviations(cov, free_param_names) for cov in covs]
448 
449     @staticmethod
450     def _deriv_with_constraints(model, param_indices, x=None, y=None):
451         if y is None:
452             d = np.array(model.fit_deriv(x, *model.parameters))
453         else:
454             d = np.array(model.fit_deriv(x, y, *model.parameters))
455 
456         if model.col_fit_deriv:
457             return d[param_indices]
458         else:
459             return d[..., param_indices]
460 
461     def _map_domain_window(self, model, x, y=None):
462         """
463         Maps domain into window for a polynomial model which has these
464         attributes.
465         """
466 
467         if y is None:
468             if hasattr(model, 'domain') and model.domain is None:
469                 model.domain = [x.min(), x.max()]
470             if hasattr(model, 'window') and model.window is None:
471                 model.window = [-1, 1]
472             return poly_map_domain(x, model.domain, model.window)
473         else:
474             if hasattr(model, 'x_domain') and model.x_domain is None:
475                 model.x_domain = [x.min(), x.max()]
476             if hasattr(model, 'y_domain') and model.y_domain is None:
477                 model.y_domain = [y.min(), y.max()]
478             if hasattr(model, 'x_window') and model.x_window is None:
479                 model.x_window = [-1., 1.]
480             if hasattr(model, 'y_window') and model.y_window is None:
481                 model.y_window = [-1., 1.]
482 
483             xnew = poly_map_domain(x, model.x_domain, model.x_window)
484             ynew = poly_map_domain(y, model.y_domain, model.y_window)
485             return xnew, ynew
486 
487     @fitter_unit_support
488     def __call__(self, model, x, y, z=None, weights=None, rcond=None):
489         """
490         Fit data to this model.
491 
492         Parameters
493         ----------
494         model : `~astropy.modeling.FittableModel`
495             model to fit to x, y, z
496         x : array
497             Input coordinates
498         y : array-like
499             Input coordinates
500         z : array-like, optional
501             Input coordinates.
502             If the dependent (``y`` or ``z``) coordinate values are provided
503             as a `numpy.ma.MaskedArray`, any masked points are ignored when
504             fitting. Note that model set fitting is significantly slower when
505             there are masked points (not just an empty mask), as the matrix
506             equation has to be solved for each model separately when their
507             coordinate grids differ.
508         weights : array, optional
509             Weights for fitting.
510             For data with Gaussian uncertainties, the weights should be
511             1/sigma.
512         rcond :  float, optional
513             Cut-off ratio for small singular values of ``a``.
514             Singular values are set to zero if they are smaller than ``rcond``
515             times the largest singular value of ``a``.
516         equivalencies : list or None, optional, keyword-only
517             List of *additional* equivalencies that are should be applied in
518             case x, y and/or z have units. Default is None.
519 
520         Returns
521         -------
522         model_copy : `~astropy.modeling.FittableModel`
523             a copy of the input model with parameters set by the fitter
524 
525         """
526 
527         if not model.fittable:
528             raise ValueError("Model must be a subclass of FittableModel")
529 
530         if not model.linear:
531             raise ModelLinearityError('Model is not linear in parameters, '
532                                       'linear fit methods should not be used.')
533 
534         if hasattr(model, "submodel_names"):
535             raise ValueError("Model must be simple, not compound")
536 
537         _validate_constraints(self.supported_constraints, model)
538 
539         model_copy = model.copy()
540         model_copy.sync_constraints = False
541         _, fitparam_indices = model_to_fit_params(model_copy)
542 
543         if model_copy.n_inputs == 2 and z is None:
544             raise ValueError("Expected x, y and z for a 2 dimensional model.")
545 
546         farg = _convert_input(x, y, z, n_models=len(model_copy),
547                               model_set_axis=model_copy.model_set_axis)
548 
549         has_fixed = any(model_copy.fixed.values())
550 
551         # This is also done by _convert_inputs, but we need it here to allow
552         # checking the array dimensionality before that gets called:
553         if weights is not None:
554             weights = np.asarray(weights, dtype=float)
555 
556         if has_fixed:
557 
558             # The list of fixed params is the complement of those being fitted:
559             fixparam_indices = [idx for idx in
560                                 range(len(model_copy.param_names))
561                                 if idx not in fitparam_indices]
562 
563             # Construct matrix of user-fixed parameters that can be dotted with
564             # the corresponding fit_deriv() terms, to evaluate corrections to
565             # the dependent variable in order to fit only the remaining terms:
566             fixparams = np.asarray([getattr(model_copy,
567                                             model_copy.param_names[idx]).value
568                                     for idx in fixparam_indices])
569 
570         if len(farg) == 2:
571             x, y = farg
572 
573             if weights is not None:
574                 # If we have separate weights for each model, apply the same
575                 # conversion as for the data, otherwise check common weights
576                 # as if for a single model:
577                 _, weights = _convert_input(
578                     x, weights,
579                     n_models=len(model_copy) if weights.ndim == y.ndim else 1,
580                     model_set_axis=model_copy.model_set_axis
581                 )
582 
583             # map domain into window
584             if hasattr(model_copy, 'domain'):
585                 x = self._map_domain_window(model_copy, x)
586             if has_fixed:
587                 lhs = np.asarray(self._deriv_with_constraints(model_copy,
588                                                               fitparam_indices,
589                                                               x=x))
590                 fixderivs = self._deriv_with_constraints(model_copy, fixparam_indices, x=x)
591             else:
592                 lhs = np.asarray(model_copy.fit_deriv(x, *model_copy.parameters))
593             sum_of_implicit_terms = model_copy.sum_of_implicit_terms(x)
594             rhs = y
595         else:
596             x, y, z = farg
597 
598             if weights is not None:
599                 # If we have separate weights for each model, apply the same
600                 # conversion as for the data, otherwise check common weights
601                 # as if for a single model:
602                 _, _, weights = _convert_input(
603                     x, y, weights,
604                     n_models=len(model_copy) if weights.ndim == z.ndim else 1,
605                     model_set_axis=model_copy.model_set_axis
606                 )
607 
608             # map domain into window
609             if hasattr(model_copy, 'x_domain'):
610                 x, y = self._map_domain_window(model_copy, x, y)
611 
612             if has_fixed:
613                 lhs = np.asarray(self._deriv_with_constraints(model_copy,
614                                                               fitparam_indices, x=x, y=y))
615                 fixderivs = self._deriv_with_constraints(model_copy,
616                                                          fixparam_indices,
617                                                          x=x, y=y)
618             else:
619                 lhs = np.asanyarray(model_copy.fit_deriv(x, y, *model_copy.parameters))
620             sum_of_implicit_terms = model_copy.sum_of_implicit_terms(x, y)
621 
622             if len(model_copy) > 1:
623 
624                 # Just to be explicit (rather than baking in False == 0):
625                 model_axis = model_copy.model_set_axis or 0
626 
627                 if z.ndim > 2:
628                     # For higher-dimensional z, flatten all the axes except the
629                     # dimension along which models are stacked and transpose so
630                     # the model axis is *last* (I think this resolves Erik's
631                     # pending generalization from 80a6f25a):
632                     rhs = np.rollaxis(z, model_axis, z.ndim)
633                     rhs = rhs.reshape(-1, rhs.shape[-1])
634                 else:
635                     # This "else" seems to handle the corner case where the
636                     # user has already flattened x/y before attempting a 2D fit
637                     # but z has a second axis for the model set. NB. This is
638                     # ~5-10x faster than using rollaxis.
639                     rhs = z.T if model_axis == 0 else z
640 
641                 if weights is not None:
642                     # Same for weights
643                     if weights.ndim > 2:
644                         # Separate 2D weights for each model:
645                         weights = np.rollaxis(weights, model_axis, weights.ndim)
646                         weights = weights.reshape(-1, weights.shape[-1])
647                     elif weights.ndim == z.ndim:
648                         # Separate, flattened weights for each model:
649                         weights = weights.T if model_axis == 0 else weights
650                     else:
651                         # Common weights for all the models:
652                         weights = weights.flatten()
653             else:
654                 rhs = z.flatten()
655                 if weights is not None:
656                     weights = weights.flatten()
657 
658         # If the derivative is defined along rows (as with non-linear models)
659         if model_copy.col_fit_deriv:
660             lhs = np.asarray(lhs).T
661 
662         # Some models (eg. Polynomial1D) don't flatten multi-dimensional inputs
663         # when constructing their Vandermonde matrix, which can lead to obscure
664         # failures below. Ultimately, np.linalg.lstsq can't handle >2D matrices,
665         # so just raise a slightly more informative error when this happens:
666         if np.asanyarray(lhs).ndim > 2:
667             raise ValueError('{} gives unsupported >2D derivative matrix for '
668                              'this x/y'.format(type(model_copy).__name__))
669 
670         # Subtract any terms fixed by the user from (a copy of) the RHS, in
671         # order to fit the remaining terms correctly:
672         if has_fixed:
673             if model_copy.col_fit_deriv:
674                 fixderivs = np.asarray(fixderivs).T  # as for lhs above
675             rhs = rhs - fixderivs.dot(fixparams)  # evaluate user-fixed terms
676 
677         # Subtract any terms implicit in the model from the RHS, which, like
678         # user-fixed terms, affect the dependent variable but are not fitted:
679         if sum_of_implicit_terms is not None:
680             # If we have a model set, the extra axis must be added to
681             # sum_of_implicit_terms as its innermost dimension, to match the
682             # dimensionality of rhs after _convert_input "rolls" it as needed
683             # by np.linalg.lstsq. The vector then gets broadcast to the right
684             # number of sets (columns). This assumes all the models share the
685             # same input coordinates, as is currently the case.
686             if len(model_copy) > 1:
687                 sum_of_implicit_terms = sum_of_implicit_terms[..., np.newaxis]
688             rhs = rhs - sum_of_implicit_terms
689 
690         if weights is not None:
691 
692             if rhs.ndim == 2:
693                 if weights.shape == rhs.shape:
694                     # separate weights for multiple models case: broadcast
695                     # lhs to have more dimension (for each model)
696                     lhs = lhs[..., np.newaxis] * weights[:, np.newaxis]
697                     rhs = rhs * weights
698                 else:
699                     lhs *= weights[:, np.newaxis]
700                     # Don't modify in-place in case rhs was the original
701                     # dependent variable array
702                     rhs = rhs * weights[:, np.newaxis]
703             else:
704                 lhs *= weights[:, np.newaxis]
705                 rhs = rhs * weights
706 
707         scl = (lhs * lhs).sum(0)
708         lhs /= scl
709 
710         masked = np.any(np.ma.getmask(rhs))
711         if weights is not None and not masked and np.any(np.isnan(lhs)):
712             raise ValueError('Found NaNs in the coefficient matrix, which '
713                              'should not happen and would crash the lapack '
714                              'routine. Maybe check that weights are not null.')
715 
716         a = None  # need for calculating covarience
717 
718         if ((masked and len(model_copy) > 1) or
719                 (weights is not None and weights.ndim > 1)):
720 
721             # Separate masks or weights for multiple models case: Numpy's
722             # lstsq supports multiple dimensions only for rhs, so we need to
723             # loop manually on the models. This may be fixed in the future
724             # with https://github.com/numpy/numpy/pull/15777.
725 
726             # Initialize empty array of coefficients and populate it one model
727             # at a time. The shape matches the number of coefficients from the
728             # Vandermonde matrix and the number of models from the RHS:
729             lacoef = np.zeros(lhs.shape[1:2] + rhs.shape[-1:], dtype=rhs.dtype)
730 
731             # Arrange the lhs as a stack of 2D matrices that we can iterate
732             # over to get the correctly-orientated lhs for each model:
733             if lhs.ndim > 2:
734                 lhs_stack = np.rollaxis(lhs, -1, 0)
735             else:
736                 lhs_stack = np.broadcast_to(lhs, rhs.shape[-1:] + lhs.shape)
737 
738             # Loop over the models and solve for each one. By this point, the
739             # model set axis is the second of two. Transpose rather than using,
740             # say, np.moveaxis(array, -1, 0), since it's slightly faster and
741             # lstsq can't handle >2D arrays anyway. This could perhaps be
742             # optimized by collecting together models with identical masks
743             # (eg. those with no rejected points) into one operation, though it
744             # will still be relatively slow when calling lstsq repeatedly.
745             for model_lhs, model_rhs, model_lacoef in zip(lhs_stack, rhs.T, lacoef.T):
746 
747                 # Cull masked points on both sides of the matrix equation:
748                 good = ~model_rhs.mask if masked else slice(None)
749                 model_lhs = model_lhs[good]
750                 model_rhs = model_rhs[good][..., np.newaxis]
751                 a = model_lhs
752 
753                 # Solve for this model:
754                 t_coef, resids, rank, sval = np.linalg.lstsq(model_lhs,
755                                                              model_rhs, rcond)
756                 model_lacoef[:] = t_coef.T
757 
758         else:
759 
760             # If we're fitting one or more models over a common set of points,
761             # we only have to solve a single matrix equation, which is an order
762             # of magnitude faster than calling lstsq() once per model below:
763 
764             good = ~rhs.mask if masked else slice(None)  # latter is a no-op
765             a = lhs[good]
766             # Solve for one or more models:
767             lacoef, resids, rank, sval = np.linalg.lstsq(lhs[good],
768                                                          rhs[good], rcond)
769 
770         self.fit_info['residuals'] = resids
771         self.fit_info['rank'] = rank
772         self.fit_info['singular_values'] = sval
773 
774         lacoef /= scl[:, np.newaxis] if scl.ndim < rhs.ndim else scl
775         self.fit_info['params'] = lacoef
776 
777         fitter_to_model_params(model_copy, lacoef.flatten())
778 
779         # TODO: Only Polynomial models currently have an _order attribute;
780         # maybe change this to read isinstance(model, PolynomialBase)
781         if hasattr(model_copy, '_order') and len(model_copy) == 1 \
782                 and not has_fixed and rank != model_copy._order:
783             warnings.warn("The fit may be poorly conditioned\n",
784                           AstropyUserWarning)
785 
786         # calculate and set covariance matrix and standard devs. on model
787         if self._calc_uncertainties:
788             if len(y) > len(lacoef):
789                 self._add_fitting_uncertainties(model_copy, a*scl,
790                                                len(lacoef), x, y, z, resids)
791         model_copy.sync_constraints = True
792         return model_copy
793 
794 
795 class FittingWithOutlierRemoval:
796     """
797     This class combines an outlier removal technique with a fitting procedure.
798     Basically, given a maximum number of iterations ``niter``, outliers are
799     removed and fitting is performed for each iteration, until no new outliers
800     are found or ``niter`` is reached.
801 
802     Parameters
803     ----------
804     fitter : `Fitter`
805         An instance of any Astropy fitter, i.e., LinearLSQFitter,
806         LevMarLSQFitter, SLSQPLSQFitter, SimplexLSQFitter, JointFitter. For
807         model set fitting, this must understand masked input data (as
808         indicated by the fitter class attribute ``supports_masked_input``).
809     outlier_func : callable
810         A function for outlier removal.
811         If this accepts an ``axis`` parameter like the `numpy` functions, the
812         appropriate value will be supplied automatically when fitting model
813         sets (unless overridden in ``outlier_kwargs``), to find outliers for
814         each model separately; otherwise, the same filtering must be performed
815         in a loop over models, which is almost an order of magnitude slower.
816     niter : int, optional
817         Maximum number of iterations.
818     outlier_kwargs : dict, optional
819         Keyword arguments for outlier_func.
820 
821     Attributes
822     ----------
823     fit_info : dict
824         The ``fit_info`` (if any) from the last iteration of the wrapped
825         ``fitter`` during the most recent fit. An entry is also added with the
826         keyword ``niter`` that records the actual number of fitting iterations
827         performed (as opposed to the user-specified maximum).
828     """
829 
830     def __init__(self, fitter, outlier_func, niter=3, **outlier_kwargs):
831         self.fitter = fitter
832         self.outlier_func = outlier_func
833         self.niter = niter
834         self.outlier_kwargs = outlier_kwargs
835         self.fit_info = {'niter': None}
836 
837     def __str__(self):
838         return ("Fitter: {0}\nOutlier function: {1}\nNum. of iterations: {2}" +
839                 ("\nOutlier func. args.: {3}"))\
840                 .format(self.fitter.__class__.__name__,
841                         self.outlier_func.__name__, self.niter,
842                         self.outlier_kwargs)
843 
844     def __repr__(self):
845         return ("{0}(fitter: {1}, outlier_func: {2}," +
846                 " niter: {3}, outlier_kwargs: {4})")\
847                  .format(self.__class__.__name__,
848                          self.fitter.__class__.__name__,
849                          self.outlier_func.__name__, self.niter,
850                          self.outlier_kwargs)
851 
852     def __call__(self, model, x, y, z=None, weights=None, **kwargs):
853         """
854         Parameters
855         ----------
856         model : `~astropy.modeling.FittableModel`
857             An analytic model which will be fit to the provided data.
858             This also contains the initial guess for an optimization
859             algorithm.
860         x : array-like
861             Input coordinates.
862         y : array-like
863             Data measurements (1D case) or input coordinates (2D case).
864         z : array-like, optional
865             Data measurements (2D case).
866         weights : array-like, optional
867             Weights to be passed to the fitter.
868         kwargs : dict, optional
869             Keyword arguments to be passed to the fitter.
870         Returns
871         -------
872         fitted_model : `~astropy.modeling.FittableModel`
873             Fitted model after outlier removal.
874         mask : `numpy.ndarray`
875             Boolean mask array, identifying which points were used in the final
876             fitting iteration (False) and which were found to be outliers or
877             were masked in the input (True).
878         """
879 
880         # For single models, the data get filtered here at each iteration and
881         # then passed to the fitter, which is the historical behavior and
882         # works even for fitters that don't understand masked arrays. For model
883         # sets, the fitter must be able to filter masked data internally,
884         # because fitters require a single set of x/y coordinates whereas the
885         # eliminated points can vary between models. To avoid this limitation,
886         # we could fall back to looping over individual model fits, but it
887         # would likely be fiddly and involve even more overhead (and the
888         # non-linear fitters don't work with model sets anyway, as of writing).
889 
890         if len(model) == 1:
891             model_set_axis = None
892         else:
893             if not hasattr(self.fitter, 'supports_masked_input') or \
894                self.fitter.supports_masked_input is not True:
895                 raise ValueError("{} cannot fit model sets with masked "
896                                  "values".format(type(self.fitter).__name__))
897 
898             # Fitters use their input model's model_set_axis to determine how
899             # their input data are stacked:
900             model_set_axis = model.model_set_axis
901         # Construct input coordinate tuples for fitters & models that are
902         # appropriate for the dimensionality being fitted:
903         if z is None:
904             coords = (x, )
905             data = y
906         else:
907             coords = x, y
908             data = z
909 
910         # For model sets, construct a numpy-standard "axis" tuple for the
911         # outlier function, to treat each model separately (if supported):
912         if model_set_axis is not None:
913 
914             if model_set_axis < 0:
915                 model_set_axis += data.ndim
916 
917             if 'axis' not in self.outlier_kwargs:  # allow user override
918                 # This also works for False (like model instantiation):
919                 self.outlier_kwargs['axis'] = tuple(
920                     n for n in range(data.ndim) if n != model_set_axis
921                 )
922 
923         loop = False
924 
925         # Starting fit, prior to any iteration and masking:
926         fitted_model = self.fitter(model, x, y, z, weights=weights, **kwargs)
927         filtered_data = np.ma.masked_array(data)
928         if filtered_data.mask is np.ma.nomask:
929             filtered_data.mask = False
930         filtered_weights = weights
931         last_n_masked = filtered_data.mask.sum()
932         n = 0  # (allow recording no. of iterations when 0)
933 
934         # Perform the iterative fitting:
935         for n in range(1, self.niter + 1):
936 
937             # (Re-)evaluate the last model:
938             model_vals = fitted_model(*coords, model_set_axis=False)
939 
940             # Determine the outliers:
941             if not loop:
942 
943                 # Pass axis parameter if outlier_func accepts it, otherwise
944                 # prepare for looping over models:
945                 try:
946                     filtered_data = self.outlier_func(
947                         filtered_data - model_vals, **self.outlier_kwargs
948                     )
949                 # If this happens to catch an error with a parameter other
950                 # than axis, the next attempt will fail accordingly:
951                 except TypeError:
952                     if model_set_axis is None:
953                         raise
954                     else:
955                         self.outlier_kwargs.pop('axis', None)
956                         loop = True
957 
958                         # Construct MaskedArray to hold filtered values:
959                         filtered_data = np.ma.masked_array(
960                             filtered_data,
961                             dtype=np.result_type(filtered_data, model_vals),
962                             copy=True
963                         )
964                         # Make sure the mask is an array, not just nomask:
965                         if filtered_data.mask is np.ma.nomask:
966                             filtered_data.mask = False
967 
968                         # Get views transposed appropriately for iteration
969                         # over the set (handling data & mask separately due to
970                         # NumPy issue #8506):
971                         data_T = np.rollaxis(filtered_data, model_set_axis, 0)
972                         mask_T = np.rollaxis(filtered_data.mask,
973                                              model_set_axis, 0)
974 
975             if loop:
976                 model_vals_T = np.rollaxis(model_vals, model_set_axis, 0)
977                 for row_data, row_mask, row_mod_vals in zip(data_T, mask_T,
978                                                             model_vals_T):
979                     masked_residuals = self.outlier_func(
980                         row_data - row_mod_vals, **self.outlier_kwargs
981                     )
982                     row_data.data[:] = masked_residuals.data
983                     row_mask[:] = masked_residuals.mask
984 
985                 # Issue speed warning after the fact, so it only shows up when
986                 # the TypeError is genuinely due to the axis argument.
987                 warnings.warn('outlier_func did not accept axis argument; '
988                               'reverted to slow loop over models.',
989                               AstropyUserWarning)
990 
991             # Recombine newly-masked residuals with model to get masked values:
992             filtered_data += model_vals
993 
994             # Re-fit the data after filtering, passing masked/unmasked values
995             # for single models / sets, respectively:
996             if model_set_axis is None:
997 
998                 good = ~filtered_data.mask
999 
1000                 if weights is not None:
1001                     filtered_weights = weights[good]
1002 
1003                 fitted_model = self.fitter(fitted_model,
1004                                            *(c[good] for c in coords),
1005                                            filtered_data.data[good],
1006                                            weights=filtered_weights, **kwargs)
1007             else:
1008                 fitted_model = self.fitter(fitted_model, *coords,
1009                                            filtered_data,
1010                                            weights=filtered_weights, **kwargs)
1011 
1012             # Stop iteration if the masked points are no longer changing (with
1013             # cumulative rejection we only need to compare how many there are):
1014             this_n_masked = filtered_data.mask.sum()  # (minimal overhead)
1015             if this_n_masked == last_n_masked:
1016                 break
1017             last_n_masked = this_n_masked
1018 
1019         self.fit_info = {'niter': n}
1020         self.fit_info.update(getattr(self.fitter, 'fit_info', {}))
1021 
1022         return fitted_model, filtered_data.mask
1023 
1024 
1025 class LevMarLSQFitter(metaclass=_FitterMeta):
1026     """
1027     Levenberg-Marquardt algorithm and least squares statistic.
1028 
1029     Attributes
1030     ----------
1031     fit_info : dict
1032         The `scipy.optimize.leastsq` result for the most recent fit (see
1033         notes).
1034 
1035     Notes
1036     -----
1037     The ``fit_info`` dictionary contains the values returned by
1038     `scipy.optimize.leastsq` for the most recent fit, including the values from
1039     the ``infodict`` dictionary it returns. See the `scipy.optimize.leastsq`
1040     documentation for details on the meaning of these values. Note that the
1041     ``x`` return value is *not* included (as it is instead the parameter values
1042     of the returned model).
1043     Additionally, one additional element of ``fit_info`` is computed whenever a
1044     model is fit, with the key 'param_cov'. The corresponding value is the
1045     covariance matrix of the parameters as a 2D numpy array.  The order of the
1046     matrix elements matches the order of the parameters in the fitted model
1047     (i.e., the same order as ``model.param_names``).
1048 
1049     """
1050 
1051     supported_constraints = ['fixed', 'tied', 'bounds']
1052     """
1053     The constraint types supported by this fitter type.
1054     """
1055 
1056     def __init__(self, calc_uncertainties=False):
1057         self.fit_info = {'nfev': None,
1058                          'fvec': None,
1059                          'fjac': None,
1060                          'ipvt': None,
1061                          'qtf': None,
1062                          'message': None,
1063                          'ierr': None,
1064                          'param_jac': None,
1065                          'param_cov': None}
1066         self._calc_uncertainties=calc_uncertainties
1067         super().__init__()
1068 
1069     def objective_function(self, fps, *args):
1070         """
1071         Function to minimize.
1072 
1073         Parameters
1074         ----------
1075         fps : list
1076             parameters returned by the fitter
1077         args : list
1078             [model, [weights], [input coordinates]]
1079 
1080         """
1081 
1082         model = args[0]
1083         weights = args[1]
1084         fitter_to_model_params(model, fps)
1085         meas = args[-1]
1086         if weights is None:
1087             return np.ravel(model(*args[2: -1]) - meas)
1088         else:
1089             return np.ravel(weights * (model(*args[2: -1]) - meas))
1090 
1091     @staticmethod
1092     def _add_fitting_uncertainties(model, cov_matrix):
1093         """
1094         Set ``cov_matrix`` and ``stds`` attributes on model with parameter
1095         covariance matrix returned by ``optimize.leastsq``.
1096         """
1097 
1098         free_param_names = [x for x in model.fixed if (model.fixed[x] is False)
1099                             and (model.tied[x] is False)]
1100 
1101         model.cov_matrix = Covariance(cov_matrix, free_param_names)
1102         model.stds = StandardDeviations(cov_matrix, free_param_names)
1103 
1104     @fitter_unit_support
1105     def __call__(self, model, x, y, z=None, weights=None,
1106                  maxiter=DEFAULT_MAXITER, acc=DEFAULT_ACC,
1107                  epsilon=DEFAULT_EPS, estimate_jacobian=False):
1108         """
1109         Fit data to this model.
1110 
1111         Parameters
1112         ----------
1113         model : `~astropy.modeling.FittableModel`
1114             model to fit to x, y, z
1115         x : array
1116            input coordinates
1117         y : array
1118            input coordinates
1119         z : array, optional
1120            input coordinates
1121         weights : array, optional
1122             Weights for fitting.
1123             For data with Gaussian uncertainties, the weights should be
1124             1/sigma.
1125         maxiter : int
1126             maximum number of iterations
1127         acc : float
1128             Relative error desired in the approximate solution
1129         epsilon : float
1130             A suitable step length for the forward-difference
1131             approximation of the Jacobian (if model.fjac=None). If
1132             epsfcn is less than the machine precision, it is
1133             assumed that the relative errors in the functions are
1134             of the order of the machine precision.
1135         estimate_jacobian : bool
1136             If False (default) and if the model has a fit_deriv method,
1137             it will be used. Otherwise the Jacobian will be estimated.
1138             If True, the Jacobian will be estimated in any case.
1139         equivalencies : list or None, optional, keyword-only
1140             List of *additional* equivalencies that are should be applied in
1141             case x, y and/or z have units. Default is None.
1142 
1143         Returns
1144         -------
1145         model_copy : `~astropy.modeling.FittableModel`
1146             a copy of the input model with parameters set by the fitter
1147 
1148         """
1149 
1150         from scipy import optimize
1151 
1152         model_copy = _validate_model(model, self.supported_constraints)
1153         model_copy.sync_constraints = False
1154         farg = (model_copy, weights, ) + _convert_input(x, y, z)
1155         if model_copy.fit_deriv is None or estimate_jacobian:
1156             dfunc = None
1157         else:
1158             dfunc = self._wrap_deriv
1159         init_values, _ = model_to_fit_params(model_copy)
1160         fitparams, cov_x, dinfo, mess, ierr = optimize.leastsq(
1161             self.objective_function, init_values, args=farg, Dfun=dfunc,
1162             col_deriv=model_copy.col_fit_deriv, maxfev=maxiter, epsfcn=epsilon,
1163             xtol=acc, full_output=True)
1164         fitter_to_model_params(model_copy, fitparams)
1165         self.fit_info.update(dinfo)
1166         self.fit_info['cov_x'] = cov_x
1167         self.fit_info['message'] = mess
1168         self.fit_info['ierr'] = ierr
1169         if ierr not in [1, 2, 3, 4]:
1170             warnings.warn("The fit may be unsuccessful; check "
1171                           "fit_info['message'] for more information.",
1172                           AstropyUserWarning)
1173 
1174         # now try to compute the true covariance matrix
1175         if (len(y) > len(init_values)) and cov_x is not None:
1176             sum_sqrs = np.sum(self.objective_function(fitparams, *farg)**2)
1177             dof = len(y) - len(init_values)
1178             self.fit_info['param_cov'] = cov_x * sum_sqrs / dof
1179         else:
1180             self.fit_info['param_cov'] = None
1181 
1182         if self._calc_uncertainties is True:
1183             if self.fit_info['param_cov'] is not None:
1184                 self._add_fitting_uncertainties(model_copy,
1185                                                self.fit_info['param_cov'])
1186 
1187         model_copy.sync_constraints = True
1188         return model_copy
1189 
1190     @staticmethod
1191     def _wrap_deriv(params, model, weights, x, y, z=None):
1192         """
1193         Wraps the method calculating the Jacobian of the function to account
1194         for model constraints.
1195         `scipy.optimize.leastsq` expects the function derivative to have the
1196         above signature (parlist, (argtuple)). In order to accommodate model
1197         constraints, instead of using p directly, we set the parameter list in
1198         this function.
1199         """
1200 
1201         if weights is None:
1202             weights = 1.0
1203 
1204         if any(model.fixed.values()) or any(model.tied.values()):
1205             # update the parameters with the current values from the fitter
1206             fitter_to_model_params(model, params)
1207             if z is None:
1208                 full = np.array(model.fit_deriv(x, *model.parameters))
1209                 if not model.col_fit_deriv:
1210                     full_deriv = np.ravel(weights) * full.T
1211                 else:
1212                     full_deriv = np.ravel(weights) * full
1213             else:
1214                 full = np.array([np.ravel(_) for _ in model.fit_deriv(x, y, *model.parameters)])
1215                 if not model.col_fit_deriv:
1216                     full_deriv = np.ravel(weights) * full.T
1217                 else:
1218                     full_deriv = np.ravel(weights) * full
1219 
1220             pars = [getattr(model, name) for name in model.param_names]
1221             fixed = [par.fixed for par in pars]
1222             tied = [par.tied for par in pars]
1223             tied = list(np.where([par.tied is not False for par in pars],
1224                                  True, tied))
1225             fix_and_tie = np.logical_or(fixed, tied)
1226             ind = np.logical_not(fix_and_tie)
1227 
1228             if not model.col_fit_deriv:
1229                 residues = np.asarray(full_deriv[np.nonzero(ind)]).T
1230             else:
1231                 residues = full_deriv[np.nonzero(ind)]
1232 
1233             return [np.ravel(_) for _ in residues]
1234         else:
1235             if z is None:
1236                 try:
1237                     return np.array([np.ravel(_) for _ in np.array(weights) *
1238                                      np.array(model.fit_deriv(x, *params))])
1239                 except ValueError:
1240                     return np.array([np.ravel(_) for _ in np.array(weights) *
1241                                      np.moveaxis(
1242                                          np.array(model.fit_deriv(x, *params)),
1243                                          -1, 0)]).transpose()
1244             else:
1245                 if not model.col_fit_deriv:
1246                     return [np.ravel(_) for _ in
1247                             (np.ravel(weights) * np.array(model.fit_deriv(x, y, *params)).T).T]
1248                 return [np.ravel(_) for _ in weights * np.array(model.fit_deriv(x, y, *params))]
1249 
1250 
1251 class SLSQPLSQFitter(Fitter):
1252     """
1253     Sequential Least Squares Programming (SLSQP) optimization algorithm and
1254     least squares statistic.
1255 
1256     Raises
1257     ------
1258     ModelLinearityError
1259         A linear model is passed to a nonlinear fitter
1260 
1261     Notes
1262     -----
1263     See also the `~astropy.modeling.optimizers.SLSQP` optimizer.
1264 
1265     """
1266 
1267     supported_constraints = SLSQP.supported_constraints
1268 
1269     def __init__(self):
1270         super().__init__(optimizer=SLSQP, statistic=leastsquare)
1271         self.fit_info = {}
1272 
1273     @fitter_unit_support
1274     def __call__(self, model, x, y, z=None, weights=None, **kwargs):
1275         """
1276         Fit data to this model.
1277 
1278         Parameters
1279         ----------
1280         model : `~astropy.modeling.FittableModel`
1281             model to fit to x, y, z
1282         x : array
1283             input coordinates
1284         y : array
1285             input coordinates
1286         z : array, optional
1287             input coordinates
1288         weights : array, optional
1289             Weights for fitting.
1290             For data with Gaussian uncertainties, the weights should be
1291             1/sigma.
1292         kwargs : dict
1293             optional keyword arguments to be passed to the optimizer or the statistic
1294         verblevel : int
1295             0-silent
1296             1-print summary upon completion,
1297             2-print summary after each iteration
1298         maxiter : int
1299             maximum number of iterations
1300         epsilon : float
1301             the step size for finite-difference derivative estimates
1302         acc : float
1303             Requested accuracy
1304         equivalencies : list or None, optional, keyword-only
1305             List of *additional* equivalencies that are should be applied in
1306             case x, y and/or z have units. Default is None.
1307 
1308         Returns
1309         -------
1310         model_copy : `~astropy.modeling.FittableModel`
1311             a copy of the input model with parameters set by the fitter
1312 
1313         """
1314 
1315         model_copy = _validate_model(model, self._opt_method.supported_constraints)
1316         model_copy.sync_constraints = False
1317         farg = _convert_input(x, y, z)
1318         farg = (model_copy, weights, ) + farg
1319         init_values, _ = model_to_fit_params(model_copy)
1320         fitparams, self.fit_info = self._opt_method(
1321             self.objective_function, init_values, farg, **kwargs)
1322         fitter_to_model_params(model_copy, fitparams)
1323 
1324         model_copy.sync_constraints = True
1325         return model_copy
1326 
1327 
1328 class SimplexLSQFitter(Fitter):
1329     """
1330     Simplex algorithm and least squares statistic.
1331 
1332     Raises
1333     ------
1334     `ModelLinearityError`
1335         A linear model is passed to a nonlinear fitter
1336 
1337     """
1338 
1339     supported_constraints = Simplex.supported_constraints
1340 
1341     def __init__(self):
1342         super().__init__(optimizer=Simplex, statistic=leastsquare)
1343         self.fit_info = {}
1344 
1345     @fitter_unit_support
1346     def __call__(self, model, x, y, z=None, weights=None, **kwargs):
1347         """
1348         Fit data to this model.
1349 
1350         Parameters
1351         ----------
1352         model : `~astropy.modeling.FittableModel`
1353             model to fit to x, y, z
1354         x : array
1355             input coordinates
1356         y : array
1357             input coordinates
1358         z : array, optional
1359             input coordinates
1360         weights : array, optional
1361             Weights for fitting.
1362             For data with Gaussian uncertainties, the weights should be
1363             1/sigma.
1364         kwargs : dict
1365             optional keyword arguments to be passed to the optimizer or the statistic
1366         maxiter : int
1367             maximum number of iterations
1368         acc : float
1369             Relative error in approximate solution
1370         equivalencies : list or None, optional, keyword-only
1371             List of *additional* equivalencies that are should be applied in
1372             case x, y and/or z have units. Default is None.
1373 
1374         Returns
1375         -------
1376         model_copy : `~astropy.modeling.FittableModel`
1377             a copy of the input model with parameters set by the fitter
1378 
1379         """
1380 
1381         model_copy = _validate_model(model,
1382                                      self._opt_method.supported_constraints)
1383         model_copy.sync_constraints = False
1384         farg = _convert_input(x, y, z)
1385         farg = (model_copy, weights, ) + farg
1386 
1387         init_values, _ = model_to_fit_params(model_copy)
1388 
1389         fitparams, self.fit_info = self._opt_method(
1390             self.objective_function, init_values, farg, **kwargs)
1391         fitter_to_model_params(model_copy, fitparams)
1392         model_copy.sync_constraints = True
1393         return model_copy
1394 
1395 
1396 class JointFitter(metaclass=_FitterMeta):
1397     """
1398     Fit models which share a parameter.
1399     For example, fit two gaussians to two data sets but keep
1400     the FWHM the same.
1401 
1402     Parameters
1403     ----------
1404     models : list
1405         a list of model instances
1406     jointparameters : list
1407         a list of joint parameters
1408     initvals : list
1409         a list of initial values
1410 
1411     """
1412 
1413     def __init__(self, models, jointparameters, initvals):
1414         self.models = list(models)
1415         self.initvals = list(initvals)
1416         self.jointparams = jointparameters
1417         self._verify_input()
1418         self.fitparams = self.model_to_fit_params()
1419 
1420         # a list of model.n_inputs
1421         self.modeldims = [m.n_inputs for m in self.models]
1422         # sum all model dimensions
1423         self.ndim = np.sum(self.modeldims)
1424 
1425     def model_to_fit_params(self):
1426         fparams = []
1427         fparams.extend(self.initvals)
1428         for model in self.models:
1429             params = model.parameters.tolist()
1430             joint_params = self.jointparams[model]
1431             param_metrics = model._param_metrics
1432             for param_name in joint_params:
1433                 slice_ = param_metrics[param_name]['slice']
1434                 del params[slice_]
1435             fparams.extend(params)
1436         return fparams
1437 
1438     def objective_function(self, fps, *args):
1439         """
1440         Function to minimize.
1441 
1442         Parameters
1443         ----------
1444         fps : list
1445             the fitted parameters - result of an one iteration of the
1446             fitting algorithm
1447         args : dict
1448             tuple of measured and input coordinates
1449             args is always passed as a tuple from optimize.leastsq
1450 
1451         """
1452 
1453         lstsqargs = list(args)
1454         fitted = []
1455         fitparams = list(fps)
1456         numjp = len(self.initvals)
1457         # make a separate list of the joint fitted parameters
1458         jointfitparams = fitparams[:numjp]
1459         del fitparams[:numjp]
1460 
1461         for model in self.models:
1462             joint_params = self.jointparams[model]
1463             margs = lstsqargs[:model.n_inputs + 1]
1464             del lstsqargs[:model.n_inputs + 1]
1465             # separate each model separately fitted parameters
1466             numfp = len(model._parameters) - len(joint_params)
1467             mfparams = fitparams[:numfp]
1468 
1469             del fitparams[:numfp]
1470             # recreate the model parameters
1471             mparams = []
1472             param_metrics = model._param_metrics
1473             for param_name in model.param_names:
1474                 if param_name in joint_params:
1475                     index = joint_params.index(param_name)
1476                     # should do this with slices in case the
1477                     # parameter is not a number
1478                     mparams.extend([jointfitparams[index]])
1479                 else:
1480                     slice_ = param_metrics[param_name]['slice']
1481                     plen = slice_.stop - slice_.start
1482                     mparams.extend(mfparams[:plen])
1483                     del mfparams[:plen]
1484             modelfit = model.evaluate(margs[:-1], *mparams)
1485             fitted.extend(modelfit - margs[-1])
1486         return np.ravel(fitted)
1487 
1488     def _verify_input(self):
1489         if len(self.models) <= 1:
1490             raise TypeError(f"Expected >1 models, {len(self.models)} is given")
1491         if len(self.jointparams.keys()) < 2:
1492             raise TypeError("At least two parameters are expected, "
1493                             "{} is given".format(len(self.jointparams.keys())))
1494         for j in self.jointparams.keys():
1495             if len(self.jointparams[j]) != len(self.initvals):
1496                 raise TypeError("{} parameter(s) provided but {} expected".format(
1497                     len(self.jointparams[j]), len(self.initvals)))
1498 
1499     def __call__(self, *args):
1500         """
1501         Fit data to these models keeping some of the parameters common to the
1502         two models.
1503         """
1504 
1505         from scipy import optimize
1506 
1507         if len(args) != reduce(lambda x, y: x + 1 + y + 1, self.modeldims):
1508             raise ValueError("Expected {} coordinates in args but {} provided"
1509                              .format(reduce(lambda x, y: x + 1 + y + 1,
1510                                             self.modeldims), len(args)))
1511 
1512         self.fitparams[:], _ = optimize.leastsq(self.objective_function,
1513                                                 self.fitparams, args=args)
1514 
1515         fparams = self.fitparams[:]
1516         numjp = len(self.initvals)
1517         # make a separate list of the joint fitted parameters
1518         jointfitparams = fparams[:numjp]
1519         del fparams[:numjp]
1520 
1521         for model in self.models:
1522             # extract each model's fitted parameters
1523             joint_params = self.jointparams[model]
1524             numfp = len(model._parameters) - len(joint_params)
1525             mfparams = fparams[:numfp]
1526 
1527             del fparams[:numfp]
1528             # recreate the model parameters
1529             mparams = []
1530             param_metrics = model._param_metrics
1531             for param_name in model.param_names:
1532                 if param_name in joint_params:
1533                     index = joint_params.index(param_name)
1534                     # should do this with slices in case the parameter
1535                     # is not a number
1536                     mparams.extend([jointfitparams[index]])
1537                 else:
1538                     slice_ = param_metrics[param_name]['slice']
1539                     plen = slice_.stop - slice_.start
1540                     mparams.extend(mfparams[:plen])
1541                     del mfparams[:plen]
1542             model.parameters = np.array(mparams)
1543 
1544 
1545 def _convert_input(x, y, z=None, n_models=1, model_set_axis=0):
1546     """Convert inputs to float arrays."""
1547 
1548     x = np.asanyarray(x, dtype=float)
1549     y = np.asanyarray(y, dtype=float)
1550 
1551     if z is not None:
1552         z = np.asanyarray(z, dtype=float)
1553         data_ndim, data_shape = z.ndim, z.shape
1554     else:
1555         data_ndim, data_shape = y.ndim, y.shape
1556 
1557     # For compatibility with how the linear fitter code currently expects to
1558     # work, shift the dependent variable's axes to the expected locations
1559     if n_models > 1 or data_ndim > x.ndim:
1560         if (model_set_axis or 0) >= data_ndim:
1561             raise ValueError("model_set_axis out of range")
1562         if data_shape[model_set_axis] != n_models:
1563             raise ValueError(
1564                 "Number of data sets (y or z array) is expected to equal "
1565                 "the number of parameter sets"
1566             )
1567         if z is None:
1568             # For a 1-D model the y coordinate's model-set-axis is expected to
1569             # be last, so that its first dimension is the same length as the x
1570             # coordinates.  This is in line with the expectations of
1571             # numpy.linalg.lstsq:
1572             # https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html
1573             # That is, each model should be represented by a column.  TODO:
1574             # Obviously this is a detail of np.linalg.lstsq and should be
1575             # handled specifically by any fitters that use it...
1576             y = np.rollaxis(y, model_set_axis, y.ndim)
1577             data_shape = y.shape[:-1]
1578         else:
1579             # Shape of z excluding model_set_axis
1580             data_shape = (z.shape[:model_set_axis] +
1581                           z.shape[model_set_axis + 1:])
1582 
1583     if z is None:
1584         if data_shape != x.shape:
1585             raise ValueError("x and y should have the same shape")
1586         farg = (x, y)
1587     else:
1588         if not (x.shape == y.shape == data_shape):
1589             raise ValueError("x, y and z should have the same shape")
1590         farg = (x, y, z)
1591     return farg
1592 
1593 
1594 # TODO: These utility functions are really particular to handling
1595 # bounds/tied/fixed constraints for scipy.optimize optimizers that do not
1596 # support them inherently; this needs to be reworked to be clear about this
1597 # distinction (and the fact that these are not necessarily applicable to any
1598 # arbitrary fitter--as evidenced for example by the fact that JointFitter has
1599 # its own versions of these)
1600 # TODO: Most of this code should be entirely rewritten; it should not be as
1601 # inefficient as it is.
1602 def fitter_to_model_params(model, fps):
1603     """
1604     Constructs the full list of model parameters from the fitted and
1605     constrained parameters.
1606     """
1607 
1608     _, fit_param_indices = model_to_fit_params(model)
1609 
1610     has_tied = any(model.tied.values())
1611     has_fixed = any(model.fixed.values())
1612     has_bound = any(b != (None, None) for b in model.bounds.values())
1613     parameters = model.parameters
1614 
1615     if not (has_tied or has_fixed or has_bound):
1616         # We can just assign directly
1617         model.parameters = fps
1618         return
1619 
1620     fit_param_indices = set(fit_param_indices)
1621     offset = 0
1622     param_metrics = model._param_metrics
1623     for idx, name in enumerate(model.param_names):
1624         if idx not in fit_param_indices:
1625             continue
1626 
1627         slice_ = param_metrics[name]['slice']
1628         shape = param_metrics[name]['shape']
1629         # This is determining which range of fps (the fitted parameters) maps
1630         # to parameters of the model
1631         size = reduce(operator.mul, shape, 1)
1632 
1633         values = fps[offset:offset + size]
1634 
1635         # Check bounds constraints
1636         if model.bounds[name] != (None, None):
1637             _min, _max = model.bounds[name]
1638             if _min is not None:
1639                 values = np.fmax(values, _min)
1640             if _max is not None:
1641                 values = np.fmin(values, _max)
1642 
1643         parameters[slice_] = values
1644         offset += size
1645 
1646     # Update model parameters before calling ``tied`` constraints.
1647     model._array_to_parameters()
1648 
1649     # This has to be done in a separate loop due to how tied parameters are
1650     # currently evaluated (the fitted parameters need to actually be *set* on
1651     # the model first, for use in evaluating the "tied" expression--it might be
1652     # better to change this at some point
1653     if has_tied:
1654         for idx, name in enumerate(model.param_names):
1655             if model.tied[name]:
1656                 value = model.tied[name](model)
1657                 slice_ = param_metrics[name]['slice']
1658 
1659                 # To handle multiple tied constraints, model parameters
1660                 # need to be updated after each iteration.
1661                 parameters[slice_] = value
1662                 model._array_to_parameters()
1663 
1664 
1665 @deprecated('5.1', 'private method: _fitter_to_model_params has been made public now')
1666 def _fitter_to_model_params(model, fps):
1667     return fitter_to_model_params(model, fps)
1668 
1669 
1670 def model_to_fit_params(model):
1671     """
1672     Convert a model instance's parameter array to an array that can be used
1673     with a fitter that doesn't natively support fixed or tied parameters.
1674     In particular, it removes fixed/tied parameters from the parameter
1675     array.
1676     These may be a subset of the model parameters, if some of them are held
1677     constant or tied.
1678     """
1679 
1680     fitparam_indices = list(range(len(model.param_names)))
1681     if any(model.fixed.values()) or any(model.tied.values()):
1682         params = list(model.parameters)
1683         param_metrics = model._param_metrics
1684         for idx, name in list(enumerate(model.param_names))[::-1]:
1685             if model.fixed[name] or model.tied[name]:
1686                 slice_ = param_metrics[name]['slice']
1687                 del params[slice_]
1688                 del fitparam_indices[idx]
1689         return (np.array(params), fitparam_indices)
1690     return (model.parameters, fitparam_indices)
1691 
1692 
1693 @deprecated('5.1', 'private method: _model_to_fit_params has been made public now')
1694 def _model_to_fit_params(model):
1695     return model_to_fit_params(model)
1696 
1697 
1698 def _validate_constraints(supported_constraints, model):
1699     """Make sure model constraints are supported by the current fitter."""
1700 
1701     message = 'Optimizer cannot handle {0} constraints.'
1702 
1703     if (any(model.fixed.values()) and
1704             'fixed' not in supported_constraints):
1705         raise UnsupportedConstraintError(
1706             message.format('fixed parameter'))
1707 
1708     if any(model.tied.values()) and 'tied' not in supported_constraints:
1709         raise UnsupportedConstraintError(
1710             message.format('tied parameter'))
1711 
1712     if (any(tuple(b) != (None, None) for b in model.bounds.values()) and
1713             'bounds' not in supported_constraints):
1714         raise UnsupportedConstraintError(
1715             message.format('bound parameter'))
1716 
1717     if model.eqcons and 'eqcons' not in supported_constraints:
1718         raise UnsupportedConstraintError(message.format('equality'))
1719 
1720     if model.ineqcons and 'ineqcons' not in supported_constraints:
1721         raise UnsupportedConstraintError(message.format('inequality'))
1722 
1723 
1724 def _validate_model(model, supported_constraints):
1725     """
1726     Check that model and fitter are compatible and return a copy of the model.
1727     """
1728 
1729     if not model.fittable:
1730         raise ValueError("Model does not appear to be fittable.")
1731     if model.linear:
1732         warnings.warn('Model is linear in parameters; '
1733                       'consider using linear fitting methods.',
1734                       AstropyUserWarning)
1735     elif len(model) != 1:
1736         # for now only single data sets ca be fitted
1737         raise ValueError("Non-linear fitters can only fit "
1738                          "one data set at a time.")
1739     _validate_constraints(supported_constraints, model)
1740 
1741     model_copy = model.copy()
1742     return model_copy
1743 
1744 
1745 def populate_entry_points(entry_points):
1746     """
1747     This injects entry points into the `astropy.modeling.fitting` namespace.
1748     This provides a means of inserting a fitting routine without requirement
1749     of it being merged into astropy's core.
1750 
1751     Parameters
1752     ----------
1753     entry_points : list of `~importlib.metadata.EntryPoint`
1754         entry_points are objects which encapsulate importable objects and
1755         are defined on the installation of a package.
1756 
1757     Notes
1758     -----
1759     An explanation of entry points can be found `here <http://setuptools.readthedocs.io/en/latest/setuptools.html#dynamic-discovery-of-services-and-plugins>`
1760     """
1761 
1762     for entry_point in entry_points:
1763         name = entry_point.name
1764         try:
1765             entry_point = entry_point.load()
1766         except Exception as e:
1767             # This stops the fitting from choking if an entry_point produces an error.
1768             warnings.warn(AstropyUserWarning(
1769                 f'{type(e).__name__} error occurred in entry point {name}.'))
1770         else:
1771             if not inspect.isclass(entry_point):
1772                 warnings.warn(AstropyUserWarning(
1773                     f'Modeling entry point {name} expected to be a Class.'))
1774             else:
1775                 if issubclass(entry_point, Fitter):
1776                     name = entry_point.__name__
1777                     globals()[name] = entry_point
1778                     __all__.append(name)
1779                 else:
1780                     warnings.warn(AstropyUserWarning(
1781                         'Modeling entry point {} expected to extend '
1782                         'astropy.modeling.Fitter' .format(name)))
1783 
1784 
1785 def _populate_ep():
1786     # TODO: Exclusively use select when Python minversion is 3.10
1787     ep = entry_points()
1788     if hasattr(ep, 'select'):
1789         populate_entry_points(ep.select(group='astropy.modeling'))
1790     else:
1791         populate_entry_points(ep.get('astropy.modeling', []))
1792 
1793 
1794 _populate_ep()
1795 
[end of astropy/modeling/fitting.py]
[start of astropy/modeling/separable.py]
1 # Licensed under a 3-clause BSD style license - see LICENSE.rst
2 
3 """
4 Functions to determine if a model is separable, i.e.
5 if the model outputs are independent.
6 
7 It analyzes ``n_inputs``, ``n_outputs`` and the operators
8 in a compound model by stepping through the transforms
9 and creating a ``coord_matrix`` of shape (``n_outputs``, ``n_inputs``).
10 
11 
12 Each modeling operator is represented by a function which
13 takes two simple models (or two ``coord_matrix`` arrays) and
14 returns an array of shape (``n_outputs``, ``n_inputs``).
15 
16 """
17 
18 import numpy as np
19 
20 from .core import Model, ModelDefinitionError, CompoundModel
21 from .mappings import Mapping
22 
23 
24 __all__ = ["is_separable", "separability_matrix"]
25 
26 
27 def is_separable(transform):
28     """
29     A separability test for the outputs of a transform.
30 
31     Parameters
32     ----------
33     transform : `~astropy.modeling.core.Model`
34         A (compound) model.
35 
36     Returns
37     -------
38     is_separable : ndarray
39         A boolean array with size ``transform.n_outputs`` where
40         each element indicates whether the output is independent
41         and the result of a separable transform.
42 
43     Examples
44     --------
45     >>> from astropy.modeling.models import Shift, Scale, Rotation2D, Polynomial2D
46     >>> is_separable(Shift(1) & Shift(2) | Scale(1) & Scale(2))
47         array([ True,  True]...)
48     >>> is_separable(Shift(1) & Shift(2) | Rotation2D(2))
49         array([False, False]...)
50     >>> is_separable(Shift(1) & Shift(2) | Mapping([0, 1, 0, 1]) | \
51         Polynomial2D(1) & Polynomial2D(2))
52         array([False, False]...)
53     >>> is_separable(Shift(1) & Shift(2) | Mapping([0, 1, 0, 1]))
54         array([ True,  True,  True,  True]...)
55 
56     """
57     if transform.n_inputs == 1 and transform.n_outputs > 1:
58         is_separable = np.array([False] * transform.n_outputs).T
59         return is_separable
60     separable_matrix = _separable(transform)
61     is_separable = separable_matrix.sum(1)
62     is_separable = np.where(is_separable != 1, False, True)
63     return is_separable
64 
65 
66 def separability_matrix(transform):
67     """
68     Compute the correlation between outputs and inputs.
69 
70     Parameters
71     ----------
72     transform : `~astropy.modeling.core.Model`
73         A (compound) model.
74 
75     Returns
76     -------
77     separable_matrix : ndarray
78         A boolean correlation matrix of shape (n_outputs, n_inputs).
79         Indicates the dependence of outputs on inputs. For completely
80         independent outputs, the diagonal elements are True and
81         off-diagonal elements are False.
82 
83     Examples
84     --------
85     >>> from astropy.modeling.models import Shift, Scale, Rotation2D, Polynomial2D
86     >>> separability_matrix(Shift(1) & Shift(2) | Scale(1) & Scale(2))
87         array([[ True, False], [False,  True]]...)
88     >>> separability_matrix(Shift(1) & Shift(2) | Rotation2D(2))
89         array([[ True,  True], [ True,  True]]...)
90     >>> separability_matrix(Shift(1) & Shift(2) | Mapping([0, 1, 0, 1]) | \
91         Polynomial2D(1) & Polynomial2D(2))
92         array([[ True,  True], [ True,  True]]...)
93     >>> separability_matrix(Shift(1) & Shift(2) | Mapping([0, 1, 0, 1]))
94         array([[ True, False], [False,  True], [ True, False], [False,  True]]...)
95 
96     """
97     if transform.n_inputs == 1 and transform.n_outputs > 1:
98         return np.ones((transform.n_outputs, transform.n_inputs),
99                        dtype=np.bool_)
100     separable_matrix = _separable(transform)
101     separable_matrix = np.where(separable_matrix != 0, True, False)
102     return separable_matrix
103 
104 
105 def _compute_n_outputs(left, right):
106     """
107     Compute the number of outputs of two models.
108 
109     The two models are the left and right model to an operation in
110     the expression tree of a compound model.
111 
112     Parameters
113     ----------
114     left, right : `astropy.modeling.Model` or ndarray
115         If input is of an array, it is the output of `coord_matrix`.
116 
117     """
118     if isinstance(left, Model):
119         lnout = left.n_outputs
120     else:
121         lnout = left.shape[0]
122     if isinstance(right, Model):
123         rnout = right.n_outputs
124     else:
125         rnout = right.shape[0]
126     noutp = lnout + rnout
127     return noutp
128 
129 
130 def _arith_oper(left, right):
131     """
132     Function corresponding to one of the arithmetic operators
133     ['+', '-'. '*', '/', '**'].
134 
135     This always returns a nonseparable output.
136 
137 
138     Parameters
139     ----------
140     left, right : `astropy.modeling.Model` or ndarray
141         If input is of an array, it is the output of `coord_matrix`.
142 
143     Returns
144     -------
145     result : ndarray
146         Result from this operation.
147     """
148     # models have the same number of inputs and outputs
149     def _n_inputs_outputs(input):
150         if isinstance(input, Model):
151             n_outputs, n_inputs = input.n_outputs, input.n_inputs
152         else:
153             n_outputs, n_inputs = input.shape
154         return n_inputs, n_outputs
155 
156     left_inputs, left_outputs = _n_inputs_outputs(left)
157     right_inputs, right_outputs = _n_inputs_outputs(right)
158 
159     if left_inputs != right_inputs or left_outputs != right_outputs:
160         raise ModelDefinitionError(
161             "Unsupported operands for arithmetic operator: left (n_inputs={}, "
162             "n_outputs={}) and right (n_inputs={}, n_outputs={}); "
163             "models must have the same n_inputs and the same "
164             "n_outputs for this operator.".format(
165                 left_inputs, left_outputs, right_inputs, right_outputs))
166 
167     result = np.ones((left_outputs, left_inputs))
168     return result
169 
170 
171 def _coord_matrix(model, pos, noutp):
172     """
173     Create an array representing inputs and outputs of a simple model.
174 
175     The array has a shape (noutp, model.n_inputs).
176 
177     Parameters
178     ----------
179     model : `astropy.modeling.Model`
180         model
181     pos : str
182         Position of this model in the expression tree.
183         One of ['left', 'right'].
184     noutp : int
185         Number of outputs of the compound model of which the input model
186         is a left or right child.
187 
188     """
189     if isinstance(model, Mapping):
190         axes = []
191         for i in model.mapping:
192             axis = np.zeros((model.n_inputs,))
193             axis[i] = 1
194             axes.append(axis)
195         m = np.vstack(axes)
196         mat = np.zeros((noutp, model.n_inputs))
197         if pos == 'left':
198             mat[: model.n_outputs, :model.n_inputs] = m
199         else:
200             mat[-model.n_outputs:, -model.n_inputs:] = m
201         return mat
202     if not model.separable:
203         # this does not work for more than 2 coordinates
204         mat = np.zeros((noutp, model.n_inputs))
205         if pos == 'left':
206             mat[:model.n_outputs, : model.n_inputs] = 1
207         else:
208             mat[-model.n_outputs:, -model.n_inputs:] = 1
209     else:
210         mat = np.zeros((noutp, model.n_inputs))
211 
212         for i in range(model.n_inputs):
213             mat[i, i] = 1
214         if pos == 'right':
215             mat = np.roll(mat, (noutp - model.n_outputs))
216     return mat
217 
218 
219 def _cstack(left, right):
220     """
221     Function corresponding to '&' operation.
222 
223     Parameters
224     ----------
225     left, right : `astropy.modeling.Model` or ndarray
226         If input is of an array, it is the output of `coord_matrix`.
227 
228     Returns
229     -------
230     result : ndarray
231         Result from this operation.
232 
233     """
234     noutp = _compute_n_outputs(left, right)
235 
236     if isinstance(left, Model):
237         cleft = _coord_matrix(left, 'left', noutp)
238     else:
239         cleft = np.zeros((noutp, left.shape[1]))
240         cleft[: left.shape[0], : left.shape[1]] = left
241     if isinstance(right, Model):
242         cright = _coord_matrix(right, 'right', noutp)
243     else:
244         cright = np.zeros((noutp, right.shape[1]))
245         cright[-right.shape[0]:, -right.shape[1]:] = 1
246 
247     return np.hstack([cleft, cright])
248 
249 
250 def _cdot(left, right):
251     """
252     Function corresponding to "|" operation.
253 
254     Parameters
255     ----------
256     left, right : `astropy.modeling.Model` or ndarray
257         If input is of an array, it is the output of `coord_matrix`.
258 
259     Returns
260     -------
261     result : ndarray
262         Result from this operation.
263     """
264 
265     left, right = right, left
266 
267     def _n_inputs_outputs(input, position):
268         """
269         Return ``n_inputs``, ``n_outputs`` for a model or coord_matrix.
270         """
271         if isinstance(input, Model):
272             coords = _coord_matrix(input, position, input.n_outputs)
273         else:
274             coords = input
275         return coords
276 
277     cleft = _n_inputs_outputs(left, 'left')
278     cright = _n_inputs_outputs(right, 'right')
279 
280     try:
281         result = np.dot(cleft, cright)
282     except ValueError:
283         raise ModelDefinitionError(
284             'Models cannot be combined with the "|" operator; '
285             'left coord_matrix is {}, right coord_matrix is {}'.format(
286                 cright, cleft))
287     return result
288 
289 
290 def _separable(transform):
291     """
292     Calculate the separability of outputs.
293 
294     Parameters
295     ----------
296     transform : `astropy.modeling.Model`
297         A transform (usually a compound model).
298 
299     Returns :
300     is_separable : ndarray of dtype np.bool
301         An array of shape (transform.n_outputs,) of boolean type
302         Each element represents the separablity of the corresponding output.
303     """
304     if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:
305         return transform_matrix
306     elif isinstance(transform, CompoundModel):
307         sepleft = _separable(transform.left)
308         sepright = _separable(transform.right)
309         return _operators[transform.op](sepleft, sepright)
310     elif isinstance(transform, Model):
311         return _coord_matrix(transform, 'left', transform.n_outputs)
312 
313 
314 # Maps modeling operators to a function computing and represents the
315 # relationship of axes as an array of 0-es and 1-s
316 _operators = {'&': _cstack, '|': _cdot, '+': _arith_oper, '-': _arith_oper,
317               '*': _arith_oper, '/': _arith_oper, '**': _arith_oper}
318 
[end of astropy/modeling/separable.py]
</code>
I need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.
<patch>
--- a/file.py
+++ b/file.py
@@ -1,27 +1,35 @@
 def euclidean(a, b):
-    while b:
-        a, b = b, a % b
-    return a
+    if b == 0:
+        return a
+    return euclidean(b, a % b)
 
 
 def bresenham(x0, y0, x1, y1):
     points = []
     dx = abs(x1 - x0)
     dy = abs(y1 - y0)
-    sx = 1 if x0 < x1 else -1
-    sy = 1 if y0 < y1 else -1
-    err = dx - dy
+    x, y = x0, y0
+    sx = -1 if x0 > x1 else 1
+    sy = -1 if y0 > y1 else 1
 
-    while True:
-        points.append((x0, y0))
-        if x0 == x1 and y0 == y1:
-            break
-        e2 = 2 * err
-        if e2 > -dy:
+    if dx > dy:
+        err = dx / 2.0
+        while x != x1:
+            points.append((x, y))
             err -= dy
-            x0 += sx
-        if e2 < dx:
-            err += dx
-            y0 += sy
+            if err < 0:
+                y += sy
+                err += dx
+            x += sx
+    else:
+        err = dy / 2.0
+        while y != y1:
+            points.append((x, y))
+            err -= dx
+            if err < 0:
+                x += sx
+                err += dy
+            y += sy
 
+    points.append((x, y))
     return points
</patch>

